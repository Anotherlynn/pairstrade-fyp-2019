{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dateparser = lambda x: pd.datetime.strptime(x, '%d/%m/%Y')\n",
    "\n",
    "data = {}\n",
    "data[\"raw\"] = pd.read_csv(\"../sample-data/hsi-top-30.csv\", parse_dates=['DateTime'], date_parser=dateparser , index_col='DateTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_names = data[\"raw\"].columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"raw\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_stocks = []\n",
    "\n",
    "for stock in stock_names:\n",
    "    index_with_negatives = data[\"raw\"].index[data[\"raw\"][stock] < 0]\n",
    "    \n",
    "    if len(index_with_negatives) > 0:\n",
    "        invalid_stocks.append(stock)\n",
    "\n",
    "invalid_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_stocks = [x for x in stock_names if x not in invalid_stocks]\n",
    "\n",
    "data[\"valid_stocks\"] = data[\"raw\"][valid_stocks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"valid_stocks_log\"] = np.log(data[\"valid_stocks\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"valid_stocks_log\"].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_k_most_correlated_pairs(df, k):\n",
    "    n_cols = len(df.columns.values.tolist())\n",
    "    \n",
    "    c = df.corr().abs()\n",
    "\n",
    "    s = c.unstack()\n",
    "    so = s.sort_values(kind=\"quicksort\")\n",
    "\n",
    "    return so[(-2*k) - n_cols:-n_cols]\n",
    "\n",
    "get_k_most_correlated_pairs(data[\"valid_stocks_log\"], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_k_most_correlated_pairs(data[\"valid_stocks_log\"][-training_size-buffer:-buffer], 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cointegration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pair_selector\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "buffer = 100\n",
    "training_size = 500\n",
    "\n",
    "cointegrated_pairs = pair_selector.coint(data[\"valid_stocks_log\"], intercept=True, sig_level=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock_pair in cointegrated_pairs:\n",
    "    print(\"Checking pair: \" + stock_pair[0] + \", \" + stock_pair[1])\n",
    "\n",
    "    plt.plot(data[\"valid_stocks_log\"][stock_pair[0]][-training_size-buffer:-buffer])\n",
    "    plt.plot(data[\"valid_stocks_log\"][stock_pair[1]][-training_size-buffer:-buffer])\n",
    "    plt.show()\n",
    "\n",
    "    X = data[\"valid_stocks_log\"][stock_pair[0]][-training_size-buffer:-buffer]\n",
    "    Y = data[\"valid_stocks_log\"][stock_pair[1]][-training_size-buffer:-buffer]\n",
    "\n",
    "    # add intercept\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    # Y = beta*X + C\n",
    "    model = sm.OLS(Y, X)\n",
    "    results = model.fit()\n",
    "    \n",
    "    print(results.params)\n",
    "\n",
    "    plt.plot(results.resid)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    ls = []\n",
    "\n",
    "    for i in range(0, buffer):\n",
    "        observed_x = data[\"valid_stocks_log\"][stock_pair[0]][-buffer + i:][0]\n",
    "        observed_y = data[\"valid_stocks_log\"][stock_pair[1]][-buffer + i:][0]\n",
    "\n",
    "        spread = (results.params[1] * observed_x + results.params[0]) - observed_y\n",
    "        ls.append(spread)\n",
    "\n",
    "    plt.plot(ls)\n",
    "    plt.show()\n",
    "\n",
    "    adfuller(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cointegrated_triplets(df, sig_level = 0.001):\n",
    "    cointegrated_triplets = []\n",
    "    \n",
    "    stock_names = df.columns.values.tolist()\n",
    "    triplets = list(itertools.combinations(stock_names, 3))\n",
    "    N = len(triplets)\n",
    "    \n",
    "    for triplet in triplets:\n",
    "        stock_1, stock_2, stock_3 = triplet\n",
    "\n",
    "        Y = df[stock_1]\n",
    "        X = df[[stock_2, stock_3]]\n",
    "        X = sm.add_constant(X)\n",
    "\n",
    "        model = sm.OLS(Y, X)\n",
    "        results = model.fit()\n",
    "\n",
    "        p_value = adfuller(results.resid)[1]\n",
    "\n",
    "        if p_value < sig_level:\n",
    "            cointegrated_triplets.append(tuple([stock_1, stock_2, stock_3]))\n",
    "            plt.plot(results.resid)\n",
    "            plt.show()\n",
    "\n",
    "    return cointegrated_triplets\n",
    "\n",
    "cointegrated_triplets = get_cointegrated_triplets(data[\"valid_stocks_log\"][-training_size-buffer:-buffer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (traders_nlp)",
   "language": "python",
   "name": "traders_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
