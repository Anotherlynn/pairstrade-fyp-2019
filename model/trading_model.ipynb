{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "from os.path import isfile, join, splitext\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"patch.force_edgecolor\"] = True\n",
    "\n",
    "from process_raw_prices import *\n",
    "\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make sure the jupyter notebook run in this working directory\n",
    "# %cd ~/fyp/code/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_pair = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of pair slices: 26680\n",
      "Total number of pair slices for training: 6000\n",
      "Total number of pair slices for validation: 3000\n",
      "Total number of pair slices for testing: 3000\n"
     ]
    }
   ],
   "source": [
    "# processed dataset folder path\n",
    "dataset_folder_path = '../../dataset/nyse-daily-transformed'\n",
    "os.makedirs(dataset_folder_path, exist_ok=True)\n",
    "\n",
    "# raw dataset files pattern\n",
    "raw_files_path_pattern = \"../../dataset/nyse-daily-trimmed-same-length/*.csv\"\n",
    "\n",
    "df_columns = ['close1', 'close2', 'normalizedLogClose1', 'normalizedLogClose2', 'spread', 'alpha', 'beta']\n",
    "ind = {'y_close': 0, 'x_close': 1, 'spread': 4}\n",
    "\n",
    "# compute dataset\n",
    "all_pairs_slices = [splitext(f)[0] for f in os.listdir(dataset_folder_path) if isfile(join(dataset_folder_path, f))]\n",
    "if len(all_pairs_slices) == 0:\n",
    "    generate_pairs_training_data(raw_files_path_pattern=raw_files_path_pattern,\n",
    "                                 result_path=dataset_folder_path,\n",
    "                                 min_size=252*4,\n",
    "                                 training_period=52,\n",
    "                                 points_per_cut=252\n",
    "                                )\n",
    "    all_pairs_slices = [splitext(f)[0] for f in os.listdir(dataset_folder_path) if isfile(join(dataset_folder_path, f))]\n",
    "print(\"Total number of pair slices: %d\" % len(all_pairs_slices))\n",
    "\n",
    "# split for training and testing\n",
    "all_pairs = sorted(list(set(['-'.join(p.split('-')[0:2]) for p in all_pairs_slices])))[:num_of_pair]\n",
    "# all_pairs = [\"VMW-WUBA\"]\n",
    "# all_pairs = [\"TWTR-UIS\"]\n",
    "all_pairs_slices_train = []\n",
    "all_pairs_slices_valid = []\n",
    "all_pairs_slices_test = []\n",
    "for p in all_pairs:\n",
    "    all_pairs_slices_train += [p+'-0', p+'-1']\n",
    "    all_pairs_slices_valid += [p+'-2']\n",
    "    all_pairs_slices_test += [p+'-3']\n",
    "print(\"Total number of pair slices for training: %d\" % len(all_pairs_slices_train))\n",
    "print(\"Total number of pair slices for validation: %d\" % len(all_pairs_slices_valid))\n",
    "print(\"Total number of pair slices for testing: %d\" % len(all_pairs_slices_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update batch size\n",
    "batch_size = 100\n",
    "\n",
    "# number of batch in training\n",
    "num_of_epoch = 120\n",
    "num_of_batch = 2*num_of_pair*num_of_epoch//batch_size\n",
    "\n",
    "# fixed number of time steps in one episode (not used)\n",
    "trading_period = 200\n",
    "\n",
    "# # 1 is zscore\n",
    "# num_features = 1\n",
    "\n",
    "# 0 is no position. 1 is long the spread. 2 is short the spread.\n",
    "a_num = position_num = 3\n",
    "\n",
    "# RNN hidden state dimension\n",
    "h_dim = 30\n",
    "\n",
    "# number of RNN layer\n",
    "num_layers = 1\n",
    "\n",
    "# number of layer1 output\n",
    "layer1_out_num = 10\n",
    "\n",
    "# learning rate\n",
    "lr = 1e-3\n",
    "\n",
    "reg = 0.0001\n",
    "\n",
    "# discount factor in reinforcement learning\n",
    "gamma = 1\n",
    "\n",
    "# random action probability lower is better...\n",
    "rand_action_prob = 0.0\n",
    "\n",
    "batches_per_print = 10*5\n",
    "\n",
    "# dummy initial cash\n",
    "initial_cash = 10000\n",
    "\n",
    "# checkpoint folder\n",
    "checkpoint_dir = '../../model_checkpoint/'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "# glob_mode should be assigned to None if an epoch finished\n",
    "glob_mode = None\n",
    "sample_start_index = None\n",
    "curr_pairs = None\n",
    "def get_random_history(batch_size, mode):\n",
    "    \"\"\"Sample some pairs and get the history of those pairs. The history should have\n",
    "    three dimension. The first dimension is for time. The second dimension is indexed\n",
    "    by features name. The third dimension is the index of training instance.\n",
    "    \"\"\"\n",
    "    global glob_mode\n",
    "    global sample_start_index\n",
    "    global curr_pairs\n",
    "    \n",
    "    if mode == 'train': # user intended to use training data\n",
    "        # first batch of training data\n",
    "        # shuffle the data first before sampling\n",
    "        if glob_mode != 'train':\n",
    "            glob_mode = 'train'\n",
    "            random.shuffle(all_pairs_slices_train)\n",
    "            sample_start_index = 0\n",
    "        sample_end_index = sample_start_index+batch_size\n",
    "        sample_pair_slices = all_pairs_slices_train[sample_start_index:sample_end_index]\n",
    "\n",
    "        # end of one epoch\n",
    "        if sample_end_index >= len(all_pairs_slices_train):\n",
    "            glob_mode = None\n",
    "\n",
    "    elif mode == 'valid': # user intended to use validation data\n",
    "        # first batch of validation data\n",
    "        # shuffle the data first before sampling\n",
    "        if glob_mode != 'valid':\n",
    "            glob_mode = 'valid'\n",
    "            random.shuffle(all_pairs_slices_valid)\n",
    "            sample_start_index = 0\n",
    "        sample_end_index = sample_start_index+batch_size\n",
    "        sample_pair_slices = all_pairs_slices_valid[sample_start_index:sample_end_index]\n",
    "\n",
    "        # end of one epoch\n",
    "        if sample_end_index >= len(all_pairs_slices_valid):\n",
    "            glob_mode = None\n",
    "    elif mode == 'test': # user intended to use validation data\n",
    "        # first batch of test data\n",
    "        # shuffle the data first before sampling\n",
    "        if glob_mode != 'test':\n",
    "            glob_mode = 'test'\n",
    "            random.shuffle(all_pairs_slices_test)\n",
    "            sample_start_index = 0\n",
    "        sample_end_index = sample_start_index+batch_size\n",
    "        sample_pair_slices = all_pairs_slices_test[sample_start_index:sample_end_index]\n",
    "\n",
    "        # end of one epoch\n",
    "        if sample_end_index >= len(all_pairs_slices_test):\n",
    "            glob_mode = None\n",
    "    else:\n",
    "        raise Exception(\"mode should be in ['train', 'valid', 'test'].\")\n",
    "    \n",
    "    curr_pairs = sample_pair_slices\n",
    "    \n",
    "    # update index for next batch\n",
    "    sample_start_index += batch_size\n",
    "    \n",
    "    # return to the environment. this should be no greater than batch_size\n",
    "    actual_batch_size = len(sample_pair_slices)\n",
    "    \n",
    "    history = []\n",
    "    for s in sample_pair_slices:\n",
    "        df = pd.read_csv(join(dataset_folder_path, s+\".csv\"))\n",
    "        df_val = df[df_columns].values\n",
    "        history.append(df_val)\n",
    "    \n",
    "    history = np.array(history)\n",
    "    return np.transpose(history, (1, 2, 0)), actual_batch_size\n",
    "\n",
    "def compute_input_history(history):\n",
    "    \"\"\"Slicing history in its second dimension.\"\"\"\n",
    "    # no slicing for now\n",
    "    return history[:,2:]\n",
    "\n",
    "def sample_action(logits, random=False, batch_size=batch_size):\n",
    "    if random:\n",
    "        dist = tf.distributions.Categorical(logits=tf.zeros([batch_size, a_num]))\n",
    "    else:\n",
    "        dist = tf.distributions.Categorical(logits=logits)\n",
    "    \n",
    "    # 1-D Tensor where the i-th element correspond to a sample from\n",
    "    # the i-th categorical distribution\n",
    "    return dist.sample()\n",
    "\n",
    "def long_portfolio_value(q, p):\n",
    "    return q*p\n",
    "\n",
    "def short_portfolio_value(q, p, init_p):\n",
    "    return q*(3.0*init_p/2 - p)\n",
    "\n",
    "# def discount_rewards(r, all_actions):\n",
    "#     \"\"\"\n",
    "#     r is a numpy array in the shape of (n, batch_size).\n",
    "#     all_actions is a numpy array in the same shape as r.\n",
    "    \n",
    "#     return the discounted and cumulative rewards\"\"\"\n",
    "    \n",
    "#     result = np.zeros_like(r, dtype=float)\n",
    "#     n = r.shape[0]\n",
    "#     sum_ = np.zeros_like(r[0], dtype=float)\n",
    "#     pre_action = all_actions[n-1]\n",
    "#     for i in range(n-1,-1,-1):\n",
    "#         sum_ *= gamma\n",
    "        \n",
    "#         # when the previous action(position) not equal to the current one,\n",
    "#         # set the previous sum of reward to be zero.\n",
    "#         sum_ = sum_*(all_actions[i]==pre_action) + r[i]\n",
    "#         result[i] = sum_\n",
    "        \n",
    "#         # update pre_action\n",
    "#         pre_action = all_actions[i]\n",
    "    \n",
    "#     return result\n",
    "\n",
    "def discount_rewards(r):\n",
    "    \"\"\"\n",
    "    r is a numpy array in the shape of (n, batch_size).\n",
    "    \n",
    "    return the discounted and cumulative rewards\"\"\"\n",
    "    \n",
    "    result = np.zeros_like(r, dtype=float)\n",
    "    n = r.shape[0]\n",
    "    sum_ = np.zeros_like(r[0], dtype=float)\n",
    "    for i in range(n-1,-1,-1):\n",
    "        sum_ *= gamma\n",
    "        sum_ += r[i]\n",
    "        result[i] = sum_\n",
    "    \n",
    "    return result\n",
    "\n",
    "def loss(all_logits, all_actions, all_advantages):\n",
    "    neg_log_select_prob = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=all_logits, labels=all_actions)\n",
    "    \n",
    "    # 0 axis is the time axis. 1 axis is the batch axis\n",
    "    return tf.reduce_mean(neg_log_select_prob * all_advantages, 0)\n",
    "\n",
    "def extract_pair_name(s):\n",
    "    return '_'.join(s.split('-')[:2])\n",
    "\n",
    "def extract_pair_index(s):\n",
    "    return int(s.split('-')[-1])\n",
    "\n",
    "def save_model():\n",
    "    hkg_time = datetime.now() + timedelta(hours=16)\n",
    "    checkpoint_name = hkg_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    checkpoint_prefix = os.path.join(checkpoint_dir, checkpoint_name)\n",
    "    root.save(checkpoint_prefix)\n",
    "    tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    \n",
    "def restore_model(checkpoint_name):\n",
    "    root.restore(join(checkpoint_dir, checkpoint_name))\n",
    "\n",
    "\n",
    "myLeakyReLU = tf.keras.layers.LeakyReLU()\n",
    "myLeakyReLU.__name__ = \"myLeakyReLU\"\n",
    "\n",
    "# classes\n",
    "class TradingPolicyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(TradingPolicyModel, self).__init__()\n",
    "        self.dense1 = tf.layers.Dense(units=layer1_out_num,\n",
    "                                      activation=myLeakyReLU,\n",
    "                                      kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                      kernel_regularizer=tf.contrib.layers.l2_regularizer(reg)\n",
    "                                     )\n",
    "        self.dense2 = tf.layers.Dense(units=layer1_out_num,\n",
    "                                      activation=myLeakyReLU,\n",
    "                                      kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                      kernel_regularizer=tf.contrib.layers.l2_regularizer(reg)\n",
    "                                     )\n",
    "        self.dense3 = tf.layers.Dense(units=layer1_out_num,\n",
    "                                      activation=myLeakyReLU,\n",
    "                                      kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                      kernel_regularizer=tf.contrib.layers.l2_regularizer(reg)\n",
    "                                     )\n",
    "#         self.dense4 = tf.layers.Dense(units=layer1_out_num,\n",
    "#                                       activation=tf.keras.layers.LeakyReLU(),\n",
    "#                                       kernel_initializer=tf.contrib.layers.xavier_initializer()\n",
    "#                                      )\n",
    "        self.logits = tf.layers.Dense(units=a_num,\n",
    "                                      activation=myLeakyReLU,\n",
    "                                      kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                      kernel_regularizer=tf.contrib.layers.l2_regularizer(reg)\n",
    "                                     )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Forward pass\n",
    "        inputs = self.dense1(inputs)\n",
    "        inputs = self.dense2(inputs)\n",
    "        inputs = self.dense3(inputs)\n",
    "#         inputs = self.dense4(inputs)\n",
    "        logits = self.logits(inputs)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class StateEncodingModel(tf.keras.Model):\n",
    "    def __init__(self, batch_size=batch_size):\n",
    "        super(StateEncodingModel, self).__init__()\n",
    "        self.cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.LSTMCell(h_dim) for i in range(num_layers)])\n",
    "        self.reset_state(batch_size)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        output, self.state = self.cell(inputs, self.state)\n",
    "        return output\n",
    "        \n",
    "    def reset_state(self, batch_size=batch_size):\n",
    "        self.state = self.cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "\n",
    "class TradingEnvironment():\n",
    "    \"\"\"Trading environment for reinforcement learning training.\n",
    "    \n",
    "    NOTE: Call reset first before calling step!\n",
    "    \n",
    "    Arguments:\n",
    "        state_encoding_model: the model that encode past input_history data into a state\n",
    "        vector which will be fed as input to the policy network.\n",
    "    \"\"\"\n",
    "    def __init__(self, state_encoding_model):\n",
    "        # do some initialization\n",
    "        self.state_encoding_model = state_encoding_model\n",
    "        \n",
    "    def _reset_env(self, mode, batch_size=batch_size):\n",
    "        \n",
    "        # prepare a batch of history and input_history\n",
    "        # actual batch_size depends on the dataset\n",
    "        self.history, curr_batch_size = get_random_history(batch_size, mode)\n",
    "        batch_size = curr_batch_size\n",
    "        self.input_history = compute_input_history(self.history)\n",
    "        \n",
    "        self.t = 0\n",
    "        self.state_encoding_model.reset_state(batch_size)\n",
    "\n",
    "        # 0 is no position. 1 is long the spread. 2 is short the spread\n",
    "        self.position = np.zeros(batch_size, dtype=int)\n",
    "        \n",
    "        # initialize the cash each agent has\n",
    "        self.total_portfolio_value = np.ones(batch_size)*initial_cash\n",
    "        \n",
    "        # only useful when there is a postion on the spread\n",
    "        self.quantity = {'x': np.zeros(batch_size), 'y': np.zeros(batch_size)}\n",
    "        \n",
    "        # for compute current portfolio value of the short side\n",
    "        self.short_side_init_price = np.zeros(batch_size)\n",
    "        \n",
    "        # create or update self.state variable\n",
    "        self.update_state()\n",
    "    \n",
    "    def reset(self, mode):\n",
    "        \"\"\"Return an initial state for the trading environment\"\"\"\n",
    "        \n",
    "        # determine what dataset to use\n",
    "        self._reset_env(mode)\n",
    "        return self.state\n",
    "    \n",
    "    def compute_reward(self, action):\n",
    "        \"\"\"Compute the reward at time t which is the change in total portfolio value\n",
    "        from time t to t+1. It also update the position for time t+1. Exit trade when\n",
    "        the short side portfolio value <= 0.\"\"\"\n",
    "        \n",
    "        r = np.zeros_like(action, dtype=float)\n",
    "        cur_his = self.history[self.t]\n",
    "        nex_his = self.history[self.t+1]\n",
    "        \n",
    "        # compute for each training instance in a batch\n",
    "        for i, a in enumerate(action):\n",
    "            y_p = cur_his[ind[\"y_close\"], i]\n",
    "            x_p = cur_his[ind[\"x_close\"], i]\n",
    "            nex_y_p = nex_his[ind[\"y_close\"], i]\n",
    "            nex_x_p = nex_his[ind[\"x_close\"], i]\n",
    "            \n",
    "            \n",
    "            if a == 0: # take no position on the spread\n",
    "                # no change in portfolio value\n",
    "                r[i] = 0\n",
    "                self.position[i] = 0\n",
    "                self.quantity['y'][i] = 0.0\n",
    "                self.quantity['x'][i] = 0.0\n",
    "            elif a == 1: # long the spread: long Y and short X\n",
    "                # quantity of each stock will change when the current position is not previous position\n",
    "                if self.position[i] == 0 or self.position[i] == 2:\n",
    "                    # compute quantity from cash\n",
    "                    self.quantity['y'][i] = 2.0*self.total_portfolio_value[i]/3.0/y_p\n",
    "                    self.quantity['x'][i] = 2.0*self.total_portfolio_value[i]/3.0/x_p\n",
    "                    self.short_side_init_price[i] = x_p\n",
    "\n",
    "                lpv = long_portfolio_value(self.quantity['y'][i], nex_y_p)\n",
    "                spv = short_portfolio_value(self.quantity['x'][i], nex_x_p, self.short_side_init_price[i])\n",
    "                \n",
    "                # the zero here can be changed to other positive threshold ...\n",
    "                if spv <= 0:\n",
    "                    # we loss all the money in the short side\n",
    "                    nex_portfolio_value = lpv\n",
    "\n",
    "                    # forced to take position 0\n",
    "                    self.position[i] = 0\n",
    "                else:\n",
    "                    nex_portfolio_value = lpv + spv\n",
    "                    self.position[i] = 1\n",
    "                \n",
    "                r[i] = nex_portfolio_value - self.total_portfolio_value[i]\n",
    "                self.total_portfolio_value[i] = nex_portfolio_value\n",
    "            elif a == 2: # short the spread: short Y and long X\n",
    "                # quantity will change when the current position is not previous position\n",
    "                if self.position[i] == 0 or self.position[i] == 1:\n",
    "                    # compute quantity from cash\n",
    "                    self.quantity['y'][i] = 2.0*self.total_portfolio_value[i]/3.0/y_p\n",
    "                    self.quantity['x'][i] = 2.0*self.total_portfolio_value[i]/3.0/x_p\n",
    "                    self.short_side_init_price[i] = y_p\n",
    "\n",
    "                lpv = long_portfolio_value(self.quantity['x'][i], nex_x_p)\n",
    "                spv = short_portfolio_value(self.quantity['y'][i], nex_y_p, self.short_side_init_price[i])\n",
    "                \n",
    "                if spv <= 0:\n",
    "                    # we loss all the money in the short side\n",
    "                    nex_portfolio_value = lpv\n",
    "\n",
    "                    # forced to take position 0\n",
    "                    self.position[i] = 0\n",
    "                else:\n",
    "                    nex_portfolio_value = lpv + spv\n",
    "                    self.position[i] = 2\n",
    "                \n",
    "                r[i] = nex_portfolio_value - self.total_portfolio_value[i]\n",
    "                self.total_portfolio_value[i] = nex_portfolio_value\n",
    "        return r\n",
    "    \n",
    "    def update_state(self):\n",
    "#         # concate next_input_history and next position to form next partial state\n",
    "#         partial_state = tf.concat([self.input_history[self.t].T, tf.one_hot(self.position, position_num)], 1)\n",
    "        \n",
    "#         # update state\n",
    "#         self.state = self.state_encoding_model(partial_state)\n",
    "\n",
    "        observation = tf.convert_to_tensor(self.input_history[self.t].T, dtype=tf.float32)\n",
    "    \n",
    "        # use rnn to encode observationans and current stock state into next stock state\n",
    "        stock_state = self.state_encoding_model(observation)\n",
    "        \n",
    "        # do normalization for total_portfolio_value\n",
    "        # this is extremely important. if not normalized, the action will be highly biased.\n",
    "        portfolio_state = np.array([\n",
    "            self.total_portfolio_value/initial_cash,\n",
    "#             self.quantity['y'],\n",
    "#             self.quantity['x']\n",
    "        ]).T\n",
    "        \n",
    "        # stock state and portfolio state together form the whole environment state\n",
    "        self.state = tf.concat([\n",
    "            stock_state,\n",
    "            portfolio_state,\n",
    "            tf.one_hot(self.position, position_num)\n",
    "        ], 1)\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"Given the current state and action, return the reward, next state and done.\n",
    "        This function should be called after reset.\n",
    "        \n",
    "        reward is of type numpy array. state is of type tensor. done is of type boolean.\n",
    "        \n",
    "        \n",
    "        Arguments:\n",
    "            action: a numpy array containing the current action for each training pair.\n",
    "\n",
    "        Note that we follow the convention where the trajectory is indexed as s_0, a_0, r_0,\n",
    "        s_1, ... . Therefore t is updated just after computing the reward is computed and\n",
    "        before computing next state.\n",
    "        \"\"\"\n",
    "        # r_t\n",
    "        r = self.compute_reward(action) # also update the position for time t+1\n",
    "\n",
    "        # t = t+1\n",
    "        self.t += 1\n",
    "        \n",
    "        # compute s_(t+1)\n",
    "        self.update_state()\n",
    "\n",
    "        return r, self.state, (self.t+1) == trading_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create objects\n",
    "pi = TradingPolicyModel()\n",
    "state_encoding_model = StateEncodingModel()\n",
    "env = TradingEnvironment(state_encoding_model)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "\n",
    "# create checkpoint object\n",
    "root = tf.train.Checkpoint(pi=pi, state_encoding_model=state_encoding_model, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batch_for_evaluate_performance(reward_list, mode):\n",
    "    done = False\n",
    "    s = env.reset(mode)\n",
    "#     print('s:', s)\n",
    "\n",
    "    # for accumalting episode statistics\n",
    "    act_batch_size = tf.shape(s).numpy()[0]\n",
    "    total_r = np.zeros(act_batch_size)\n",
    "\n",
    "    # internally the episode length is fixed by trading_period\n",
    "    while not done:\n",
    "        logits = pi(s)\n",
    "        a = sample_action(logits, batch_size=act_batch_size)\n",
    "\n",
    "        # get immediate reward, update state, and get done\n",
    "        r, s, done = env.step(a.numpy())\n",
    "\n",
    "#         # for debugging\n",
    "#         print('logits:', logits)\n",
    "#         print('a:', a.numpy())\n",
    "#         print('r:', r)\n",
    "#         print('s:', s)\n",
    "\n",
    "        total_r += r\n",
    "    reward_list += total_r.tolist()\n",
    "    return {extract_pair_name(curr_pairs[i]): total_r[i] for i in range(act_batch_size)}\n",
    "\n",
    "\n",
    "def run_epoch_for_evaluate_performance(rs, total_r_dict, mode):\n",
    "    counter = 0\n",
    "    temp_dict = run_batch_for_evaluate_performance(rs, mode)\n",
    "    total_r_dict.update(temp_dict)\n",
    "    print('{}, '.format(counter), end='')\n",
    "    counter += 1\n",
    "    while glob_mode != None:\n",
    "        temp_dict = run_batch_for_evaluate_performance(rs, mode)\n",
    "        total_r_dict.update(temp_dict)\n",
    "        print('{}, '.format(counter), end='')\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 6000\n",
      "5.9237205519861895\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmAAAAEyCAYAAABdxWyxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAFh9JREFUeJzt3XuMZvV5H/Dv010gtdsEMGt7uxfA\nycotjdqGrjCpJcsyKRcXeYlkJKworByqVVucpnWtgOs/iBJFMm1aJ1ZdKmKIobKMHTcRK4TrbIkt\nq5IhXhybi4nDBht2uJi1wDSq5Rjo0z/mbDteZi/M5TczO5+PdPSe85zfOef37pmZ97vn8p7q7gAA\nMM5fW+kOAACsNwIYAMBgAhgAwGACGADAYAIYAMBgAhgAwGACGADAYAIYAMBgAhgAwGAbV7oDx3LW\nWWf1Oeecs9LdAAA4rvvvv/+73b3pRNqu6gB2zjnnZP/+/SvdDQCA46qqx0+07XFPQVbVrVX1bFU9\nNM+8D1RVV9VZ03RV1Uer6kBVPVBV589pu7uqHp2G3SfaQQCAk82JXAP2iSSXHlmsqm1J/nGSJ+aU\nL0uyYxr2JLlpantmkhuSvCXJBUluqKozFtNxAIC16rgBrLu/lOS5eWZ9JMmvJuk5tV1Jbu9Z9yY5\nvao2J7kkyb7ufq67n0+yL/OEOgCA9WBBd0FW1buSPNndXz9i1pYkB+dMz0y1o9UBANadV30RflW9\nJsmHklw83+x5an2M+nzr35PZ05fZvn37q+0eAMCqt5AjYD+Z5NwkX6+qbyfZmuSrVfXGzB7Z2jan\n7dYkTx2j/grdfXN37+zunZs2ndCdnAAAa8qrDmDd/WB3v767z+nuczIbrs7v7meS7E1y9XQ35IVJ\nXujup5N8PsnFVXXGdPH9xVMNAGDdOZGvofhUki8neXNVzVTVNcdofneSx5IcSPK7Sf5FknT3c0l+\nI8lXpuHXpxoAwLpT3fNeirUq7Ny5s30RKwCwFlTV/d2980TaehYkAMBgAhgAwGACGOva5q3bU1XL\nOmze6utUAPhRq/ph3LDcnnnyYM6+7q5l3cbjN16+rOsHYO1xBAwAYDABDABgMAEMAGAwAQwAYDAB\nDABgMAEMAGAwAQwAYDABDABgMAEMAGAwAQwAYDABDABgMAEMAGAwAQwAYDABDABgMAEMAGAwAQwA\nYDABDABgMAEMAGAwAQwAYDABDABgMAEMAGAwAQwAYDABDABgMAEMAGAwAQwAYLDjBrCqurWqnq2q\nh+bU/n1V/VlVPVBVf1hVp8+Z98GqOlBV36yqS+bUL51qB6rq+qV/KwAAa8OJHAH7RJJLj6jtS/LT\n3f33kvx5kg8mSVWdl+SqJH93WuY/V9WGqtqQ5GNJLktyXpL3TG0BANad4waw7v5SkueOqP1Rd780\nTd6bZOs0vivJHd39V939rSQHklwwDQe6+7Hu/mGSO6a2AADrzlJcA/ZLST43jW9JcnDOvJmpdrQ6\nAMC6s6gAVlUfSvJSkk8eLs3TrI9Rn2+de6pqf1XtP3To0GK6BwCwKi04gFXV7iSXJ/mF7j4cpmaS\nbJvTbGuSp45Rf4Xuvrm7d3b3zk2bNi20ewAAq9aCAlhVXZrkuiTv6u7vz5m1N8lVVXVaVZ2bZEeS\nP0nylSQ7qurcqjo1sxfq711c1wEA1qaNx2tQVZ9K8vYkZ1XVTJIbMnvX42lJ9lVVktzb3f+sux+u\nqs8k+UZmT01e290vT+t5X5LPJ9mQ5NbufngZ3g8AwKp33ADW3e+Zp3zLMdr/ZpLfnKd+d5K7X1Xv\nAABOQr4JHwBgMAEMAGAwAQwAYDABDABgMAEMAGAwAQyW24ZTUlXLOmzeun2l3yUAr8Jxv4YCWKSX\nX8zZ1921rJt4/MbLl3X9ACwtR8AAAAYTwAAABhPAAAAGE8AAAAYTwAAABhPAAAAGE8AAAAYTwAAA\nBhPAAAAGE8AAAAYTwAAABhPAWJU2b92+7A+wrqqVfpsArFMexs2q9MyTB5f9AdaJh1gDsDIcAQMA\nGEwAAwAYTAADABhMAAMAGEwAAwAYTAADABhMAAMAGEwAAwAYTAADABjsuAGsqm6tqmer6qE5tTOr\nal9VPTq9njHVq6o+WlUHquqBqjp/zjK7p/aPVtXu5Xk7AACr34kcAftEkkuPqF2f5J7u3pHknmk6\nSS5LsmMa9iS5KZkNbEluSPKWJBckueFwaAMAWG+OG8C6+0tJnjuivCvJbdP4bUmumFO/vWfdm+T0\nqtqc5JIk+7r7ue5+Psm+vDLUAQCsCwu9BuwN3f10kkyvr5/qW5IcnNNuZqodrQ4AsO4s9UX4NU+t\nj1F/5Qqq9lTV/qraf+jQoSXtHADAarDQAPad6dRiptdnp/pMkm1z2m1N8tQx6q/Q3Td3987u3rlp\n06YFdg8AYPVaaADbm+TwnYy7k9w5p371dDfkhUlemE5Rfj7JxVV1xnTx/cVTDQBg3dl4vAZV9akk\nb09yVlXNZPZuxg8n+UxVXZPkiSRXTs3vTvLOJAeSfD/Je5Oku5+rqt9I8pWp3a9395EX9gMArAvH\nDWDd/Z6jzLponrad5NqjrOfWJLe+qt4BAJyEfBM+AMBgAhgAwGACGADAYAIYAMBgAhgAwGACGADA\nYAIYAMBgAhgAwGACGADAYAIYAMBgAhgAwGACGADAYAIYAMBgAhgAwGACGADAYAIYAMBgAhgAwGAC\nGADAYAIYAMBgAhgAwGACGADAYAIYAMBgAhgAwGACGADAYAIYAMBgAhgAwGACGADAYAIYAMBgAhgA\nwGCLCmBV9a+r6uGqeqiqPlVVP1ZV51bVfVX1aFV9uqpOndqeNk0fmOafsxRvAABgrVlwAKuqLUn+\nZZKd3f3TSTYkuSrJjUk+0t07kjyf5JppkWuSPN/dP5XkI1M7AIB1Z7GnIDcm+etVtTHJa5I8neQd\nST47zb8tyRXT+K5pOtP8i6qqFrl9AIA1Z8EBrLufTPJbSZ7IbPB6Icn9Sb7X3S9NzWaSbJnGtyQ5\nOC370tT+dQvdPgDAWrWYU5BnZPao1rlJ/laS1ya5bJ6mfXiRY8ybu949VbW/qvYfOnRood0DAFi1\nFnMK8ueSfKu7D3X3i0n+IMk/SnL6dEoySbYmeWoan0myLUmm+T+R5LkjV9rdN3f3zu7euWnTpkV0\nDwBgdVpMAHsiyYVV9ZrpWq6LknwjyReSvHtqszvJndP43mk60/w/7u5XHAEDADjZLeYasPsyezH9\nV5M8OK3r5iTXJXl/VR3I7DVet0yL3JLkdVP9/UmuX0S/AQDWrI3Hb3J03X1DkhuOKD+W5IJ52v4g\nyZWL2R4AwMnAN+EDAAwmgAEADCaAAQAMJoABAAwmgAEADCaAAQAMJoABAAwmgAEADCaAAQAMJoAB\nAAwmgAEADCaAwclgwympqmUfNm/dvtLvFOCksKiHcQOrxMsv5uzr7lr2zTx+4+XLvg2A9cARMACA\nwQQwAIDBBDAAgMEEMACAwQQwAIDBBDAAgMEEMACAwQQwAIDBBDAAgMEEMACAwQQwAIDBBDAAgMEE\nMACAwQQwAIDBBDAAgMEEMACAwRYVwKrq9Kr6bFX9WVU9UlU/W1VnVtW+qnp0ej1jaltV9dGqOlBV\nD1TV+UvzFgAA1pbFHgH7nST/vbv/dpK/n+SRJNcnuae7dyS5Z5pOksuS7JiGPUluWuS2AQDWpAUH\nsKr68SRvS3JLknT3D7v7e0l2JbltanZbkium8V1Jbu9Z9yY5vao2L7jnAABr1GKOgL0pyaEkv1dV\nf1pVH6+q1yZ5Q3c/nSTT6+un9luSHJyz/MxUAwBYVxYTwDYmOT/JTd39M0n+d/7/6cb51Dy1fkWj\nqj1Vtb+q9h86dGgR3QMAWJ0WE8Bmksx0933T9GczG8i+c/jU4vT67Jz22+YsvzXJU0eutLtv7u6d\n3b1z06ZNi+geAMDqtOAA1t3PJDlYVW+eShcl+UaSvUl2T7XdSe6cxvcmuXq6G/LCJC8cPlUJALCe\nbFzk8r+c5JNVdWqSx5K8N7Oh7jNVdU2SJ5JcObW9O8k7kxxI8v2pLQDAurOoANbdX0uyc55ZF83T\ntpNcu5jtAQCcDHwTPgDAYAIYr9rmrdtTVcs6AMDJbLHXgLEOPfPkwZx93V3Luo3Hb7x8WdcPACvJ\nETAAgMEEMACAwQQwAIDBBDAAgMEEMACAwQQwAIDBBDAAgMEEMACAwQQwAIDBBDAAgMEEMACAwQQw\nAIDBBDAAgMEEMACAwQQwAIDBBDAAgMEEMACAwQQwAIDBBDAAgMEEMACAwQQwAIDBBDAAgMEEMACA\nwQQwAIDBBDAAgMEEMACAwRYdwKpqQ1X9aVXdNU2fW1X3VdWjVfXpqjp1qp82TR+Y5p+z2G0DAKxF\nS3EE7FeSPDJn+sYkH+nuHUmeT3LNVL8myfPd/VNJPjK1AwBYdxYVwKpqa5J/kuTj03QleUeSz05N\nbktyxTS+a5rONP+iqT0AwLqy2CNgv53kV5P8n2n6dUm+190vTdMzSbZM41uSHEySaf4LU3sAgHVl\nwQGsqi5P8mx33z+3PE/TPoF5c9e7p6r2V9X+Q4cOLbR7AACr1mKOgL01ybuq6ttJ7sjsqcffTnJ6\nVW2c2mxN8tQ0PpNkW5JM838iyXNHrrS7b+7und29c9OmTYvoHrDkNpySqlrWYfPW7Sv9LgGW3cbj\nN5lfd38wyQeTpKrenuQD3f0LVfX7Sd6d2VC2O8md0yJ7p+kvT/P/uLtfcQQMWMVefjFnX3fXsm7i\n8RsvX9b1A6wGy/E9YNcleX9VHcjsNV63TPVbkrxuqr8/yfXLsG0AgFVvwUfA5uruLyb54jT+WJIL\n5mnzgyRXLsX2AADWMt+EDwAwmAAGADCYAAYAMJgABgAwmAAGADCYAAYAMJgABgAwmAAGADCYAAYA\nMJgABgAwmAAGADCYAAYAMJgABgAwmAAGADCYAAYAMJgABgAwmAAGADCYAAYAMJgABgAwmAAGADCY\nAAYAMJgABgAwmAAGADCYAAYAMJgAdpLZvHV7qmpZBwBgcTaudAdYWs88eTBnX3fXsm7j8RsvX9b1\nA8DJzhEwAIDBBDAAgMEEMACAwRYcwKpqW1V9oaoeqaqHq+pXpvqZVbWvqh6dXs+Y6lVVH62qA1X1\nQFWdv1RvAgBgLVnMEbCXkvyb7v47SS5Mcm1VnZfk+iT3dPeOJPdM00lyWZId07AnyU2L2DYAwJq1\n4ADW3U9391en8b9M8kiSLUl2JbltanZbkium8V1Jbu9Z9yY5vao2L7jnAABr1JJcA1ZV5yT5mST3\nJXlDdz+dzIa0JK+fmm1JcnDOYjNTDQBgXVl0AKuqv5HkvyX5V939v47VdJ5az7O+PVW1v6r2Hzp0\naLHdAwBYdRYVwKrqlMyGr0929x9M5e8cPrU4vT471WeSbJuz+NYkTx25zu6+ubt3dvfOTZs2LaZ7\nAACr0mLugqwktyR5pLv/45xZe5PsnsZ3J7lzTv3q6W7IC5O8cPhUJQDAerKYRxG9NckvJnmwqr42\n1f5tkg8n+UxVXZPkiSRXTvPuTvLOJAeSfD/JexexbeBkteGUZX/m6Bu3bMvTM08s6zYAjmXBAay7\n/2fmv64rSS6ap30nuXah2wPWiZdf9DxT4KTnm/ABAAYTwAAABhPAAAAGE8AAAAYTwAAABhPAAAAG\nE8AAAAYTwAAABhPAAAAGE8AAAAYTwAAABhPAAAAGE8AAAAYTwID1Z8MpqaplHzZv3b7S7xRYpTau\ndAcAhnv5xZx93V3LvpnHb7x82bcBrE2OgAEADCaAAQAMJoABAAwmgAEADCaADbJ56/Yhd10BAKuf\nuyAHeebJg+66AgCSOAIGADCcAAYAMJgABgAwmAAGsFwGPPLI445gbXIRPsByGfDIIzfewNrkCBgA\nwGACGMBaNuA0p1OdsPScggRYywac5kySx3/r55f9y57fuGVbnp55Ylm3AavF8ABWVZcm+Z0kG5J8\nvLs/PLoPALxKrmeDJTX0FGRVbUjysSSXJTkvyXuq6ryRfZjPiMcEAQAcNvoI2AVJDnT3Y0lSVXck\n2ZXkG4P78SNGPCbI/+wAVt7mrdvzzJMHl307TqdyPKMD2JYkc3/yZ5K8ZXAfAFiNphsKltvJcs3c\nhlN/LC//8AdrfhvJ+gys1d3jNlZ1ZZJLuvufTtO/mOSC7v7lOW32JNkzTb45yTeHdXDtOivJd1e6\nE7yC/bJ62Terk/2yetk3J+bs7t50Ig1HHwGbSbJtzvTWJE/NbdDdNye5eWSn1rqq2t/dO1e6H/wo\n+2X1sm9WJ/tl9bJvlt7o7wH7SpIdVXVuVZ2a5Kokewf3AQBgRQ09AtbdL1XV+5J8PrNfQ3Frdz88\nsg8AACtt+PeAdffdSe4evd2TnFO2q5P9snrZN6uT/bJ62TdLbOhF+AAAeBYkAMBwAhgAwGAC2CpX\nVb9WVU9W1dem4Z1z5n2wqg5U1Ter6pI59Uun2oGqun5O/dyquq+qHq2qT093orIMjrYPWD5V9e2q\nenD6Pdk/1c6sqn3Tz/y+qjpjqldVfXTaPw9U1flz1rN7av9oVe1eqfezllXVrVX1bFU9NKe2ZPui\nqv7htK8PTMt63tsJOMp+8RmzUrrbsIqHJL+W5APz1M9L8vUkpyU5N8lfZPbO0g3T+JuSnDq1OW9a\n5jNJrprG/0uSf77S7+9kHI61DwzL+u/+7SRnHVH7d0mun8avT3LjNP7OJJ9LUkkuTHLfVD8zyWPT\n6xnT+Bkr/d7W2pDkbUnOT/LQcuyLJH+S5GenZT6X5LKVfs9rYTjKfvEZs0KDI2Br164kd3T3X3X3\nt5IcyOyzNv/f8za7+4dJ7kiya/of4juSfHZa/rYkV6xAv9eDeffBCvdpvdqV2Z/15Ed/5nclub1n\n3Zvk9KranOSSJPu6+7nufj7JviSXju70WtfdX0ry3BHlJdkX07wf7+4v9+wn/e3xt+yEHGW/HI3P\nmGUmgK0N75sOzd96+LB95n+u5pZj1F+X5Hvd/dIRdZbe0fYBy6uT/FFV3T890ixJ3tDdTyfJ9Pr6\nqf5qf39YvKXaF1um8SPrLJzPmBUggK0CVfU/quqheYZdSW5K8pNJ/kGSp5P8h8OLzbOqXkCdpeff\nemW8tbvPT3JZkmur6m3HaOv3ZPXwt2xl+YxZIcO/iJVX6u6fO5F2VfW7Se6aJo/1XM356t/N7KH9\njdP/UF7xHE6WzHGfecrS6+6nptdnq+oPM3uq5DtVtbm7n55OXT07NT/aPppJ8vYj6l9c5q6vF0u1\nL2am8SPbswDd/Z3D4z5jxnIEbJWb/lAd9vNJDt+9sjfJVVV1WlWdm2RHZi9Mnfd5m9O1El9I8u5p\n+d1J7hzxHtYhzzwdrKpeW1V/8/B4kosz+7uyN7M/68mP/szvTXL1dAfehUlemE6LfT7JxVV1xnQq\n5uKpxuItyb6Y5v1lVV04XXd0dfwtWzCfMStope8CMBx7SPJfkzyY5IHM/kJsnjPvQ5m9G+WbmXMX\nUGbvKvrzad6H5tTflNlfoANJfj/JaSv9/k7W4Wj7wLBs/95vyuzdWF9P8vDhf/PMXpdyT5JHp9cz\np3ol+di0fx5MsnPOun5p+h05kOS9K/3e1uKQ5FOZPZ31YmaPpFyzlPsiyc7MBoW/SPKfMj3VxbCg\n/eIzZoUGjyICABjMKUgAgMEEMACAwQQwAIDBBDAAgMEEMACAwQQwAIDBBDAAgMH+L4ra7quFrkwg\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15056d8eacf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate performance on train dataset\n",
    "train_rs = []\n",
    "train_total_r_dict = {}\n",
    "run_epoch_for_evaluate_performance(train_rs, train_total_r_dict, 'train')\n",
    "\n",
    "print(len(train_rs))\n",
    "print(np.mean(train_rs))\n",
    "plt.hist(train_rs, bins=20)\n",
    "plt.gcf().set_size_inches(10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_of_pair = 3000\n",
      "batch_size = 100\n",
      "num_of_batch = 7200, estimated epoch = 120.0\n",
      "rand_action_prob = 0.0\n",
      "lr = 0.001\n",
      "batch_id: 49, num_eps_over: 5000, average_total_r_per_ep: 96.63, time_spent: 68.7s\n",
      "average total_r over one epoch: 101.55\n",
      "batch_id: 99, num_eps_over: 5000, average_total_r_per_ep: 357.95, time_spent: 68.9s\n",
      "average total_r over one epoch: 562.58\n",
      "batch_id: 149, num_eps_over: 5000, average_total_r_per_ep: 1012.99, time_spent: 70.6s\n",
      "average total_r over one epoch: 1221.33\n",
      "batch_id: 199, num_eps_over: 5000, average_total_r_per_ep: 1367.27, time_spent: 71.7s\n",
      "average total_r over one epoch: 1660.85\n",
      "batch_id: 249, num_eps_over: 5000, average_total_r_per_ep: 1805.26, time_spent: 67.1s\n",
      "batch_id: 299, num_eps_over: 5000, average_total_r_per_ep: 2317.13, time_spent: 69.9s\n",
      "average total_r over one epoch: 2251.38\n",
      "batch_id: 349, num_eps_over: 5000, average_total_r_per_ep: 2436.32, time_spent: 71.1s\n",
      "average total_r over one epoch: 2467.78\n",
      "batch_id: 399, num_eps_over: 5000, average_total_r_per_ep: 2630.95, time_spent: 69.7s\n",
      "average total_r over one epoch: 2680.57\n",
      "batch_id: 449, num_eps_over: 5000, average_total_r_per_ep: 2745.99, time_spent: 67.6s\n",
      "average total_r over one epoch: 2736.49\n",
      "batch_id: 499, num_eps_over: 5000, average_total_r_per_ep: 2726.92, time_spent: 70.3s\n",
      "average total_r over one epoch: 2742.34\n",
      "batch_id: 549, num_eps_over: 5000, average_total_r_per_ep: 2777.11, time_spent: 69.2s\n",
      "batch_id: 599, num_eps_over: 5000, average_total_r_per_ep: 2778.31, time_spent: 68.7s\n",
      "average total_r over one epoch: 2785.82\n",
      "batch_id: 649, num_eps_over: 5000, average_total_r_per_ep: 2820.56, time_spent: 70.5s\n",
      "average total_r over one epoch: 2840.18\n",
      "batch_id: 699, num_eps_over: 5000, average_total_r_per_ep: 2878.68, time_spent: 71.0s\n",
      "average total_r over one epoch: 2867.60\n",
      "batch_id: 749, num_eps_over: 5000, average_total_r_per_ep: 2832.32, time_spent: 67.7s\n",
      "average total_r over one epoch: 2802.43\n",
      "batch_id: 799, num_eps_over: 5000, average_total_r_per_ep: 2767.94, time_spent: 69.0s\n",
      "average total_r over one epoch: 2817.65\n",
      "batch_id: 849, num_eps_over: 5000, average_total_r_per_ep: 2842.99, time_spent: 70.7s\n",
      "batch_id: 899, num_eps_over: 5000, average_total_r_per_ep: 2665.48, time_spent: 66.8s\n",
      "average total_r over one epoch: 2678.80\n",
      "batch_id: 949, num_eps_over: 5000, average_total_r_per_ep: 2799.24, time_spent: 70.3s\n",
      "average total_r over one epoch: 2788.82\n",
      "batch_id: 999, num_eps_over: 5000, average_total_r_per_ep: 2807.55, time_spent: 71.1s\n",
      "average total_r over one epoch: 2807.59\n",
      "batch_id: 1049, num_eps_over: 5000, average_total_r_per_ep: 2826.25, time_spent: 70.8s\n",
      "average total_r over one epoch: 2837.85\n",
      "batch_id: 1099, num_eps_over: 5000, average_total_r_per_ep: 2796.99, time_spent: 66.6s\n",
      "average total_r over one epoch: 2860.34\n",
      "batch_id: 1149, num_eps_over: 5000, average_total_r_per_ep: 2930.00, time_spent: 69.6s\n",
      "batch_id: 1199, num_eps_over: 5000, average_total_r_per_ep: 2832.26, time_spent: 69.7s\n",
      "average total_r over one epoch: 2865.64\n",
      "batch_id: 1249, num_eps_over: 5000, average_total_r_per_ep: 2881.28, time_spent: 69.4s\n",
      "average total_r over one epoch: 2865.99\n",
      "batch_id: 1299, num_eps_over: 5000, average_total_r_per_ep: 2770.81, time_spent: 69.0s\n",
      "average total_r over one epoch: 2764.28\n",
      "batch_id: 1349, num_eps_over: 5000, average_total_r_per_ep: 2785.77, time_spent: 70.4s\n",
      "average total_r over one epoch: 2806.57\n",
      "batch_id: 1399, num_eps_over: 5000, average_total_r_per_ep: 2826.83, time_spent: 69.1s\n",
      "average total_r over one epoch: 2819.87\n",
      "batch_id: 1449, num_eps_over: 5000, average_total_r_per_ep: 2769.87, time_spent: 68.1s\n",
      "batch_id: 1499, num_eps_over: 5000, average_total_r_per_ep: 2824.69, time_spent: 70.2s\n",
      "average total_r over one epoch: 2792.67\n",
      "batch_id: 1549, num_eps_over: 5000, average_total_r_per_ep: 2868.89, time_spent: 71.6s\n",
      "average total_r over one epoch: 2856.56\n",
      "batch_id: 1599, num_eps_over: 5000, average_total_r_per_ep: 2795.25, time_spent: 68.0s\n",
      "average total_r over one epoch: 2791.88\n",
      "batch_id: 1649, num_eps_over: 5000, average_total_r_per_ep: 2814.47, time_spent: 69.2s\n",
      "average total_r over one epoch: 2849.12\n",
      "batch_id: 1699, num_eps_over: 5000, average_total_r_per_ep: 2839.22, time_spent: 70.7s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-41bae666878c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# episode starts here~\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# for accumalting episode statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-99de4208469b>\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;31m# determine what dataset to use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-99de4208469b>\u001b[0m in \u001b[0;36m_reset_env\u001b[0;34m(self, mode, batch_size)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# prepare a batch of history and input_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;31m# actual batch_size depends on the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_random_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_input_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-99de4208469b>\u001b[0m in \u001b[0;36mget_random_history\u001b[0;34m(batch_size, mode)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_pair_slices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_folder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mdf_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1067\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'as_recarray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1837\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_integer_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m     \"\"\"\n\u001b[1;32m    779\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# print parameters\n",
    "print('num_of_pair =', num_of_pair)\n",
    "print('batch_size =', batch_size)\n",
    "print('num_of_batch = {}, estimated epoch = {}'.format(num_of_batch, num_of_batch*batch_size/2/num_of_pair))\n",
    "print('rand_action_prob =', rand_action_prob)\n",
    "print('lr =', lr)\n",
    "\n",
    "# for training reference only\n",
    "average_total_r = 0.0\n",
    "epoch_average_total_r = 0.0\n",
    "num_eps_over = 0\n",
    "total_r_dict = {}\n",
    "\n",
    "start_time = time.time()\n",
    "for batch in range(num_of_batch):\n",
    "    \n",
    "    with tf.GradientTape() as gt:\n",
    "        # saving for update\n",
    "        all_logits = []\n",
    "        all_actions = []\n",
    "        all_rewards = []\n",
    "        \n",
    "        # episode starts here~\n",
    "        done = False\n",
    "        s = env.reset('train')\n",
    "        \n",
    "        # for accumalting episode statistics\n",
    "        act_batch_size = tf.shape(s).numpy()[0]\n",
    "        num_eps_over += act_batch_size\n",
    "        total_r = np.zeros(act_batch_size)\n",
    "\n",
    "        # internally the episode length is fixed by trading_period\n",
    "        while not done:\n",
    "            logits = pi(s)\n",
    "            a = sample_action(logits, random=np.random.rand() <= rand_action_prob,\n",
    "                              batch_size=act_batch_size)\n",
    "            r, s, done = env.step(a.numpy())\n",
    "\n",
    "            # save the episode\n",
    "            all_logits.append(logits)\n",
    "            all_actions.append(a)\n",
    "            all_rewards.append(r)\n",
    "            \n",
    "            r_sum = np.sum(r)\n",
    "            average_total_r += r_sum\n",
    "            epoch_average_total_r += r_sum\n",
    "            total_r += r\n",
    "            \n",
    "#             # debugging\n",
    "#             print(env.t)\n",
    "#             print(env.t+1==200)\n",
    "#             print(r[0])\n",
    "#             print('a:', a.numpy())\n",
    "#             print(env.total_portfolio_value[0])\n",
    "#             print(done)\n",
    "#             print(logits)\n",
    "\n",
    "        # keep track of the pair performance (of course this is not totally fair for all pairs\n",
    "        # as there are parameters update).\n",
    "        total_r_dict.update({curr_pairs[i]: total_r[i] for i in range(act_batch_size)})\n",
    "\n",
    "        all_logits_stack = tf.stack(all_logits)\n",
    "        all_actions_stack = tf.stack(all_actions)\n",
    "        all_rewards_stack = np.array(all_rewards)\n",
    "        \n",
    "        # compute cummulative rewards for each action\n",
    "        all_cum_rewards = discount_rewards(all_rewards_stack)\n",
    "#         all_cum_rewards -= np.mean(all_cum_rewards)\n",
    "#         all_cum_rewards /= np.std(all_cum_rewards)\n",
    "        all_cum_rewards /= np.mean(np.abs(all_cum_rewards))\n",
    "        all_cum_rewards = tf.convert_to_tensor(all_cum_rewards, dtype=tf.float32)\n",
    "\n",
    "        loss_value = loss(all_logits_stack, all_actions_stack, all_cum_rewards)\n",
    "    \n",
    "    grads = gt.gradient(loss_value, state_encoding_model.variables + pi.variables)\n",
    "    optimizer.apply_gradients(zip(grads, state_encoding_model.variables + pi.variables))\n",
    "    \n",
    "    if (batch+1) % batches_per_print == 0:\n",
    "        end_time = time.time()\n",
    "        print((\"batch_id: {}, num_eps_over: {}, average_total_r_per_ep: {:.2f}, \"+\n",
    "               \"time_spent: {:.1f}s\").format(\n",
    "            batch, num_eps_over, average_total_r/num_eps_over, end_time-start_time))\n",
    "        \n",
    "        # reset\n",
    "        average_total_r = 0.0\n",
    "        num_eps_over = 0\n",
    "        start_time = time.time()\n",
    "    \n",
    "    # print epoch summary\n",
    "    if glob_mode == None:\n",
    "        # compute average total reward in one epoch to evaluate agent performance\n",
    "        print(\"average total_r over one epoch: {:.2f}\".format(\n",
    "            epoch_average_total_r/len(total_r_dict)))\n",
    "        \n",
    "        # reset\n",
    "        epoch_average_total_r = 0.0\n",
    "        total_r_dict = {}\n",
    "        \n",
    "print('Finished training~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 6000\n",
      "2845.3169521630793\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmwAAAEyCAYAAABH+Yw/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x150564298860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate performance on train dataset\n",
    "train_rs = []\n",
    "train_total_r_dict = {}\n",
    "run_epoch_for_evaluate_performance(train_rs, train_total_r_dict, 'train')\n",
    "\n",
    "print(len(train_rs))\n",
    "print(np.mean(train_rs))\n",
    "plt.hist(train_rs, bins=20)\n",
    "plt.gcf().set_size_inches(10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 3000\n",
      "1961.125412271524\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAAEyCAYAAADJI8VDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAQAMIGQBAAwgZAEADCBkAQAM8P8AhByLzHE+3j8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1505647ca6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate performance on valid dataset\n",
    "valid_rs = []\n",
    "valid_total_r_dict = {}\n",
    "run_epoch_for_evaluate_performance(valid_rs, valid_total_r_dict, 'valid')\n",
    "\n",
    "print(len(valid_rs))\n",
    "print(np.mean(valid_rs))\n",
    "plt.hist(valid_rs, bins=20)\n",
    "plt.gcf().set_size_inches(10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 3000\n",
      "2349.781248385228\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAAEyCAYAAADJI8VDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAFd5JREFUeJzt3X/sXtV9H/D3ZzYkW5oUCIZZ/tqY\nrFbW/BNCrZQqU5SFNgkM1UwKElVVLMbkaSJVom4adP1jnbQ/wqQ1K1rFxEI2U6UhNG2EhegPz0lU\nVRo0JiHkB01xWMBfbLDTJCQbSkPY2R/PcfPFfO3vY/s53x/26yVd3XvPPc9zzz2+fvz2uc99brXW\nAgDAbP2dlW4AAMDZSMgCABhAyAIAGEDIAgAYQMgCABhAyAIAGEDIAgAYQMgCABhAyAIAGGD9Sjcg\nSS6++OK2devWlW4GAMCSHn300W+11jYsVW9VhKytW7dm//79K90MAIAlVdXT09RzuRAAYAAhCwBg\nACELAGAAIQsAYAAhCwBgACELAGAAIQsAYAAhCwBgACELAGAAIQsAYAAhCwBgACGLFbVxbkuqaui0\ncW7LSh8mAOegVfGAaM5dzz17MJfd9uDQfTx9x3VD3x8AFmMkCwBgACELAGAAIQsAYAAhCwBgACEL\nAGAAIQsAYAAhCwBgACELAGAAIQsAYAAhCwBgACELAGCAJUNWVb25qh5bMH2vqj5UVRdV1d6qerLP\nL+z1q6rurKoDVfV4VV05/jAAAFaXJUNWa+3rrbUrWmtXJPmZJC8m+XSS25Psa61tS7KvryfJNUm2\n9WlXkrtGNBwAYDU71cuFVyf5Rmvt6SQ7kuzu5buTXN+XdyS5t008nOSCqto4k9YCAKwRpxqybkzy\nib58aWvtcJL0+SW9fFOSgwteM9/LAADOGVOHrKo6P8kvJvn9paouUtYWeb9dVbW/qvYfPXp02mYA\nAKwJpzKSdU2SL7TWnu/rzx+7DNjnR3r5fJLNC143l+TQ8W/WWru7tba9tbZ9w4YNp95yAIBV7FRC\n1i/lx5cKk2RPkp19eWeSBxaU39TvMrwqyQvHLisCAJwr1k9Tqar+XpJfSPIvFhR/OMn9VXVLkmeS\n3NDLH0pybZIDmdyJePPMWgsAsEZMFbJaay8meeNxZX+dyd2Gx9dtSW6dSesAANYov/gOADCAkAUA\nMICQBQAwgJAFADCAkAUAMICQBQAwgJAFADCAkAUAMICQBQAwgJAFADCAkAUAMICQBQAwgJAFADCA\nkAUAMICQBQAwgJAFADCAkAUAMICQBQAwgJAFADCAkAUAMICQBQAwgJAFADCAkAUAMICQBQAwgJAF\nADCAkAUAMMBUIauqLqiqT1XVX1bVE1X1c1V1UVXtraon+/zCXreq6s6qOlBVj1fVlWMPAQBg9Zl2\nJOu3k/xxa+0fJnlrkieS3J5kX2ttW5J9fT1JrkmyrU+7ktw10xYDAKwBS4asqnpDkncmuSdJWms/\nbK19N8mOJLt7td1Jru/LO5Lc2yYeTnJBVW2cecsBAFaxaUay3pTkaJL/XlVfrKqPVtXrklzaWjuc\nJH1+Sa+/KcnBBa+f72WvUFW7qmp/Ve0/evToGR0EAMBqM03IWp/kyiR3tdbeluT/5seXBhdTi5S1\nVxW0dndrbXtrbfuGDRumaiwAwFoxTciaTzLfWnukr38qk9D1/LHLgH1+ZEH9zQteP5fk0GyaC6dh\n3XmpquHTxrktK32kAKwi65eq0Fp7rqoOVtWbW2tfT3J1kq/1aWeSD/f5A/0le5J8oKruS/KzSV44\ndlkRVsTLL+Wy2x4cvpun77hu+D4AWDuWDFndryb5eFWdn+SpJDdnMgp2f1XdkuSZJDf0ug8luTbJ\ngSQv9roAAOeUqUJWa+2xJNsX2XT1InVbklvPsF0AAGuaX3wHABhAyAIAGEDIAgAYQMgCABhAyAIA\nGEDIAgAYQMgCABhAyAIAGEDIAgAYQMgCABhAyAIAGEDIAgAYQMgCABhAyAIAGEDIAgAYQMgCABhA\nyAIAGEDIAgAYQMgCABhAyAIAGEDIAgAYQMgCABhAyAIAGEDIAgAYQMgCABhgqpBVVd+sqi9X1WNV\ntb+XXVRVe6vqyT6/sJdXVd1ZVQeq6vGqunLkAQAArEanMpL1j1trV7TWtvf125Psa61tS7KvryfJ\nNUm29WlXkrtm1VgAgLXiTC4X7kiyuy/vTnL9gvJ728TDSS6oqo1nsB8AgDVn2pDVkvxpVT1aVbt6\n2aWttcNJ0ueX9PJNSQ4ueO18LwMAOGesn7LeO1prh6rqkiR7q+ovT1K3Filrr6o0CWu7kmTLli1T\nNgMAYG2YaiSrtXaoz48k+XSStyd5/thlwD4/0qvPJ9m84OVzSQ4t8p53t9a2t9a2b9iw4fSPAABg\nFVoyZFXV66rq9ceWk7wnyVeS7Emys1fbmeSBvrwnyU39LsOrkrxw7LIia8vGuS2pqqETAJytprlc\neGmST/d/ENcn+b3W2h9X1eeT3F9VtyR5JskNvf5DSa5NciDJi0lunnmrWRbPPXswl9324NB9PH3H\ndUPfHwBWypIhq7X2VJK3LlL+10muXqS8Jbl1Jq0DAFij/OI7AMAAQhYAwABCFgDAAEIWAMAAQhYA\nwABCFgDAAEIWAMAAQhYAwABCFgDAAEIWAMAAQhYAwABCFgDAAEIWAMAAQhYAwABCFgDAAEIWAMAA\nQhYAwABCFgDAAEIWAMAAQhYAwABCFgDAAEIWAMAAQhYAwABCFgDAAEIWAMAAQhYAwABTh6yqWldV\nX6yqB/v65VX1SFU9WVWfrKrze/lr+vqBvn3rmKYDAKxepzKS9cEkTyxYvyPJR1pr25J8J8ktvfyW\nJN9prf1Uko/0egAA55SpQlZVzSX5J0k+2tcrybuTfKpX2Z3k+r68o6+nb7+61wcAOGdMO5L1n5P8\nmyT/r6+/Mcl3W2s/6uvzSTb15U1JDiZJ3/5Cr/8KVbWrqvZX1f6jR4+eZvNhFVl3Xqpq6LRxbstK\nHyUAU1q/VIWqui7Jkdbao1X1rmPFi1RtU2z7cUFrdye5O0m2b9/+qu2w5rz8Ui677cGhu3j6juuG\nvj8As7NkyEryjiS/WFXXJnltkjdkMrJ1QVWt76NVc0kO9frzSTYnma+q9Ul+Msm3Z95yAIBVbMnL\nha21X2+tzbXWtia5MclnWmu/nOSzSd7fq+1M8kBf3tPX07d/prVmpAoAOKecye9k3Zbk16rqQCbf\nubqnl9+T5I29/NeS3H5mTQQAWHumuVz4t1prn0vyub78VJK3L1LnB0lumEHbAADWLL/4DgAwgJAF\nADCAkAUAMICQBQAwgJAFADCAkAUAMICQBQAwgJAFADCAkAUAMICQBQAwgJAFADCAkAUAMICQBQAw\ngJAFADCAkAUAMICQBQAwgJAFADCAkAUAMICQBQAwgJAFADCAkAUAMICQBQAwgJAFADCAkAUAMICQ\nBQAwgJAFADDAkiGrql5bVX9RVV+qqq9W1b/v5ZdX1SNV9WRVfbKqzu/lr+nrB/r2rWMPAQBg9Zlm\nJOtvkry7tfbWJFckeV9VXZXkjiQfaa1tS/KdJLf0+rck+U5r7aeSfKTXAwA4pywZstrE/+mr5/Wp\nJXl3kk/18t1Jru/LO/p6+varq6pm1mIAgDVgqu9kVdW6qnosyZEke5N8I8l3W2s/6lXmk2zqy5uS\nHEySvv2FJG9c5D13VdX+qtp/9OjRMzsKAIBVZqqQ1Vp7ubV2RZK5JG9P8tOLVevzxUat2qsKWru7\ntba9tbZ9w4YN07YXAGBNOKW7C1tr303yuSRXJbmgqtb3TXNJDvXl+SSbk6Rv/8kk355FYwEA1opp\n7i7cUFUX9OW/m+TnkzyR5LNJ3t+r7UzyQF/e09fTt3+mtfaqkSwAgLPZ+qWrZGOS3VW1LpNQdn9r\n7cGq+lqS+6rqPyT5YpJ7ev17kvxuVR3IZATrxgHtBgBY1ZYMWa21x5O8bZHypzL5ftbx5T9IcsNM\nWgcAsEb5xXcAgAGELACAAYQsAIABhCwAgAGELACAAYQsAIABhCwAgAGELACAAYQsAIABhCwAgAGE\nLACAAYQsAIABhCwAgAGELACAAYQsAIABhCwAgAGELFhL1p2Xqho6bZzbstJHCXBWWL/SDQBOwcsv\n5bLbHhy6i6fvuG7o+wOcK4xkAQAMIGQBAAwgZAEADCBkAQAMIGQBAAwgZAEADCBkAQAMsGTIqqrN\nVfXZqnqiqr5aVR/s5RdV1d6qerLPL+zlVVV3VtWBqnq8qq4cfRAAAKvNNCNZP0ryr1prP53kqiS3\nVtVbktyeZF9rbVuSfX09Sa5Jsq1Pu5LcNfNWAwCsckuGrNba4dbaF/ry95M8kWRTkh1Jdvdqu5Nc\n35d3JLm3TTyc5IKq2jjzlgMArGKn9J2sqtqa5G1JHklyaWvtcDIJYkku6dU2JTm44GXzvQwA4Jwx\ndciqqp9I8gdJPtRa+97Jqi5S1hZ5v11Vtb+q9h89enTaZgAArAlThayqOi+TgPXx1tof9uLnj10G\n7PMjvXw+yeYFL59Lcuj492yt3d1a295a275hw4bTbT8AwKo0zd2FleSeJE+01n5rwaY9SXb25Z1J\nHlhQflO/y/CqJC8cu6wIAHCuWD9FnXck+ZUkX66qx3rZv03y4ST3V9UtSZ5JckPf9lCSa5McSPJi\nkptn2mIAgDVgyZDVWvvzLP49qyS5epH6LcmtZ9guAIA1zS++AwAMIGQBAAwgZAEADCBkAQAMIGQB\nAAwgZAEADCBkAQAMIGQBAAwgZK1BG+e2pKqGTwDA6ZvmsTqsMs89ezCX3fbg8P08fcd1w/cBAGcr\nI1kAAAMIWQAAAwhZAAADCFkAAAMIWQAAAwhZAAADCFkAAAMIWQAAAwhZAAADCFnAK607b1ke27Rx\nbstKHynAUB6rA7zSyy95bBPADBjJAgAYQMgCABhAyAIAGEDIAgAYQMgCABhgyZBVVR+rqiNV9ZUF\nZRdV1d6qerLPL+zlVVV3VtWBqnq8qq4c2XgAgNVqmpGs/5HkfceV3Z5kX2ttW5J9fT1JrkmyrU+7\nktw1m2YCAKwtS4as1tqfJfn2ccU7kuzuy7uTXL+g/N428XCSC6pq46waCwCwVpzud7Iuba0dTpI+\nv6SXb0pycEG9+V72KlW1q6r2V9X+o0ePnmYzAABWp1l/8b0WKWuLVWyt3d1a295a275hw4YZNwMA\nYGWdbsh6/thlwD4/0svnk2xeUG8uyaHTbx4AwNp0uiFrT5KdfXlnkgcWlN/U7zK8KskLxy4rAgCc\nS5Z8QHRVfSLJu5JcXFXzSf5dkg8nub+qbknyTJIbevWHklyb5ECSF5PcPKDNAACr3pIhq7X2SyfY\ndPUidVuSW8+0UQAAa51ffAcAGEDIAlbGuvNSVUOnjXNbVvoogXPYkpcLAYZ4+aVcdtuDQ3fx9B3X\nDX1/gJMxkgUAMICQBQAwgJAFADCAkAUAMICQBQAwgJAFADCAkAUAMICQBQAwgJAFADCAkAWcvTy6\nB1hBHqsDnL08ugdYQUayAAAGELJmbOPcluGXJwCA1c/lwhl77tmDLk8AAEayAABGELIAAAYQsgAA\nBhCyAM7EMvwWl9/jgrXJF98BzsQy/BZX4oYXWIuMZAEADCBkAQAMIGQBrAWewwhrzpDvZFXV+5L8\ndpJ1ST7aWvvwiP0AnDM8hxHWnJmHrKpal+R3kvxCkvkkn6+qPa21r816XwDMUB8tG76b81+bl3/4\ng6H7+PubNufw/DND9wFLGTGS9fYkB1prTyVJVd2XZEcSIQtgNVvGOyXPhlG5jXNb8tyzB4fvR2Bc\nu0aErE1JFp5180l+dsB+Tsly/WUAYBVYplG5s+XnO5bj38jlGMFMVlcordbabN+w6oYk722t/fO+\n/itJ3t5a+9Xj6u1KsquvvjnJ12fakJO7OMm3lnF/5zr9vfz0+fLT58tLfy8/ff5jl7XWNixVacRI\n1nySzQvW55IcOr5Sa+3uJHcP2P+Sqmp/a237Suz7XKS/l58+X376fHnp7+Wnz0/diJ9w+HySbVV1\neVWdn+TGJHsG7AcAYNWa+UhWa+1HVfWBJH+SyU84fKy19tVZ7wcAYDUb8jtZrbWHkjw04r1nZEUu\nU57D9Pfy0+fLT58vL/29/PT5KZr5F98BAPBYHQCAIYQsAIABzrqQVVW/WVXPVtVjfbp2wbZfr6oD\nVfX1qnrvgvL39bIDVXX7gvLLq+qRqnqyqj7Z75bkFJyobzl1VfXNqvpyP6/397KLqmpvP0f3VtWF\nvbyq6s7e749X1ZUL3mdnr/9kVe1cqeNZjarqY1V1pKq+sqBsZn1cVT/T/wwP9NeO/7XMVe4Efe5z\nfJCq2lxVn62qJ6rqq1X1wV7uPB+htXZWTUl+M8m/XqT8LUm+lOQ1SS5P8o1M7n5c15fflOT8Xuct\n/TX3J7mxL//XJP9ypY9vLU0n61vTafXnN5NcfFzZf0xye1++PckdffnaJH+UpJJcleSRXn5Rkqf6\n/MK+fOFKH9tqmZK8M8mVSb4yoo+T/EWSn+uv+aMk16z0Ma/0dII+9zk+rr83JrmyL78+yV/1fnWe\nD5jOupGsk9iR5L7W2t+01v53kgOZPGfxb5+12Fr7YZL7kuzoyfvdST7VX787yfUr0O61bNG+XeE2\nnW12ZHJuJq88R3ckubdNPJzkgqramOS9Sfa21r7dWvtOkr1J3rfcjV6tWmt/luTbxxXPpI/7tje0\n1v5Xm/xLdG98ppyoz0/E5/gZaq0dbq19oS9/P8kTmTwOz3k+wNkasj7QhzU/dmzIM4s/U3HTScrf\nmOS7rbUfHVfO9E7Ut5yeluRPq+rRmjyWKkkuba0dTiYfnkku6eWner5zYrPq4019+fhyFudzfLCq\n2prkbUkeifN8iDUZsqrqf1bVVxaZdiS5K8k/SHJFksNJ/tOxly3yVu00ypmePpytd7TWrkxyTZJb\nq+qdJ6nrvB7PZ8o4PscHq6qfSPIHST7UWvveyaouUqbPpzTkx0hHa639/DT1quq/JTn2iPSTPVNx\nsfJvZTIsur7/L2jRZzByUlM9x5LptNYO9fmRqvp0JpdInq+qja21w32Y/kivfqK+n0/yruPKPze4\n6WvdrPp4vi8fX5/jtNaeP7bsc3z2quq8TALWx1trf9iLnecDrMmRrJPpJ8cx/zTJsTtW9iS5sape\nU1WXJ9mWyZfzFn3WYr+W/Nkk7++v35nkgeU4hrOI51jOSFW9rqpef2w5yXsyObf3ZHJuJq88R/ck\nuanfGXRVkhf6JYA/SfKeqrqwX4J5Ty/jxGbSx33b96vqqv5doZviM2VRPsfH6efePUmeaK391oJN\nzvMRVvqb97Oekvxuki8neTyTk2Pjgm2/kckdKF/PgrsdMrl74q/6tt9YUP6mTP4CH0jy+0les9LH\nt9amE/Wt6ZT78U2Z3DH1pSRfPdaXmXznZF+SJ/v8ol5eSX6n9/uXk2xf8F7/rJ/TB5LcvNLHtpqm\nJJ/I5PLUS5n8j/yWWfZxku2ZBIZvJPkv6U/dOJenE/S5z/Fx/f2PMrl893iSx/p0rfN8zOSxOgAA\nA5x1lwsBAFYDIQsAYAAhCwBgACELAGAAIQsAYAAhCwBgACELAGCA/w/KCJDBuVUHCAAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15056478f3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate performance on test dataset\n",
    "test_rs = []\n",
    "test_total_r_dict = {}\n",
    "run_epoch_for_evaluate_performance(test_rs, test_total_r_dict, 'test')\n",
    "\n",
    "print(len(test_rs))\n",
    "print(np.mean(test_rs))\n",
    "plt.hist(test_rs, bins=20)\n",
    "plt.gcf().set_size_inches(10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAEyCAYAAADnZuTRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ng9AEANBBaAIA6PD/AY0DfDuPtGGjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15056f76f668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pick best K pairs from train result and see how good those pairs are in valid\n",
    "K = 20\n",
    "train_total_r_ordered = sorted(list(train_total_r_dict.items()), key=lambda x: x[1], reverse=True)\n",
    "train_total_r_ordered_sliced = train_total_r_ordered[:K]\n",
    "valid_total_r_sliced = [(x[0], valid_total_r_dict[x[0]]) for x in train_total_r_ordered_sliced]\n",
    "valid_total_r_corresponding_value = [x[1] for x in valid_total_r_sliced]\n",
    "train_total_r_sliced_value = [x[1] for x in train_total_r_ordered_sliced]\n",
    "\n",
    "# see if the model overfits a lot by checking the performace in valid of best K pairs in train\n",
    "bins = np.linspace(-10000, 20000, 30)\n",
    "plt.hist(train_total_r_sliced_value, bins, alpha=0.3, label='train')\n",
    "plt.hist(valid_total_r_corresponding_value, bins, alpha=0.3, label='valid')\n",
    "plt.legend(loc='upper right')\n",
    "plt.gcf().set_size_inches(10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAEyCAYAAADnZuTRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1505642651d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pick best K pairs from valid result and see how good those pairs are in test\n",
    "K = 20\n",
    "valid_total_r_ordered = sorted(list(valid_total_r_dict.items()), key=lambda x: x[1], reverse=True)\n",
    "valid_total_r_ordered_sliced = valid_total_r_ordered[:K]\n",
    "test_total_r_sliced = [(x[0], test_total_r_dict[x[0]]) for x in valid_total_r_ordered_sliced]\n",
    "test_total_r_corresponding_value = [x[1] for x in test_total_r_sliced]\n",
    "valid_total_r_sliced_value = [x[1] for x in valid_total_r_ordered_sliced]\n",
    "\n",
    "# see if the model overfits a lot by checking the performace in valid of best K pairs in train\n",
    "bins = np.linspace(-10000, 20000, 30)\n",
    "plt.hist(valid_total_r_sliced_value, bins, alpha=0.3, label='valid')\n",
    "plt.hist(test_total_r_corresponding_value, bins, alpha=0.3, label='test')\n",
    "plt.legend(loc='upper right')\n",
    "plt.gcf().set_size_inches(10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DQ_RENN', -3070.1054612203006),\n",
       " ('BITA_JKS', 5427.880164286684),\n",
       " ('CAI_TYL', 1821.499487912777),\n",
       " ('CAI_HIVE', 3979.439402515858),\n",
       " ('BITA_UMC', -909.0883976882524),\n",
       " ('CMCM_NPTN', 923.1101221470835),\n",
       " ('ASGN_SMI', 2286.673201915655),\n",
       " ('CAI_SPA', 7370.706584626045),\n",
       " ('BITA_HIVE', 2500.904811166194),\n",
       " ('CAI_SRT', 6381.191193018731),\n",
       " ('BITA_SRT', 3202.2439778786647),\n",
       " ('AAN_SPA', 6592.802282782286),\n",
       " ('CLS_DDD', 14795.101331369031),\n",
       " ('BITA_RNG', -1653.3169140655446),\n",
       " ('AAN_SMI', -44.38880406807948),\n",
       " ('CSLT_GLOB', 40.05322197955684),\n",
       " ('ATHM_SMI', 7172.807296806481),\n",
       " ('BITA_SAP', 445.8191350308334),\n",
       " ('CMCM_CSLT', 3283.6623297204515),\n",
       " ('AAN_TBI', 1986.2462966888197)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_total_r_sliced"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel, 2018 update 2)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_2018u2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
