{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "from os.path import isfile, join, splitext\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"patch.force_edgecolor\"] = True\n",
    "\n",
    "from process_raw_prices import *\n",
    "\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make sure the jupyter notebook run in this working directory\n",
    "# %cd ~/fyp/code/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_pair = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of pair slices: 26680\n",
      "Total number of pair slices for training: 2000\n",
      "Total number of pair slices for validation: 1000\n",
      "Total number of pair slices for testing: 1000\n"
     ]
    }
   ],
   "source": [
    "# processed dataset folder path\n",
    "dataset_folder_path = '../../dataset/nyse-daily-transformed'\n",
    "os.makedirs(dataset_folder_path, exist_ok=True)\n",
    "\n",
    "# raw dataset files pattern\n",
    "raw_files_path_pattern = \"../../dataset/nyse-daily-trimmed-same-length/*.csv\"\n",
    "\n",
    "df_columns = ['close1', 'close2', 'normalizedLogClose1', 'normalizedLogClose2', 'spread', 'alpha', 'beta']\n",
    "ind = {'y_close': 0, 'x_close': 1, 'spread': 4}\n",
    "\n",
    "# compute dataset\n",
    "all_pairs_slices = [splitext(f)[0] for f in os.listdir(dataset_folder_path) if isfile(join(dataset_folder_path, f))]\n",
    "if len(all_pairs_slices) == 0:\n",
    "    generate_pairs_training_data(raw_files_path_pattern=raw_files_path_pattern,\n",
    "                                 result_path=dataset_folder_path,\n",
    "                                 min_size=252*4,\n",
    "                                 training_period=52,\n",
    "                                 points_per_cut=252\n",
    "                                )\n",
    "    all_pairs_slices = [splitext(f)[0] for f in os.listdir(dataset_folder_path) if isfile(join(dataset_folder_path, f))]\n",
    "print(\"Total number of pair slices: %d\" % len(all_pairs_slices))\n",
    "\n",
    "# split for training and testing\n",
    "all_pairs = sorted(list(set(['-'.join(p.split('-')[0:2]) for p in all_pairs_slices])))[:num_of_pair]\n",
    "# all_pairs = [\"VMW-WUBA\"]\n",
    "# all_pairs = [\"TWTR-UIS\"]\n",
    "all_pairs_slices_train = []\n",
    "all_pairs_slices_valid = []\n",
    "all_pairs_slices_test = []\n",
    "for p in all_pairs:\n",
    "    all_pairs_slices_train += [p+'-0', p+'-1']\n",
    "    all_pairs_slices_valid += [p+'-2']\n",
    "    all_pairs_slices_test += [p+'-3']\n",
    "print(\"Total number of pair slices for training: %d\" % len(all_pairs_slices_train))\n",
    "print(\"Total number of pair slices for validation: %d\" % len(all_pairs_slices_valid))\n",
    "print(\"Total number of pair slices for testing: %d\" % len(all_pairs_slices_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update batch size\n",
    "batch_size = 100\n",
    "\n",
    "# number of batch in training\n",
    "num_of_epoch = 20\n",
    "num_of_batch = 2*num_of_pair*num_of_epoch//batch_size\n",
    "\n",
    "# fixed number of time steps in one episode (not used)\n",
    "trading_period = 200\n",
    "\n",
    "# # 1 is zscore\n",
    "# num_features = 1\n",
    "\n",
    "# 0 is no position. 1 is long the spread. 2 is short the spread.\n",
    "a_num = position_num = 3\n",
    "\n",
    "# RNN hidden state dimension\n",
    "h_dim = 30\n",
    "\n",
    "# number of RNN layer\n",
    "num_layers = 1\n",
    "\n",
    "# number of layer1 output\n",
    "layer1_out_num = 10\n",
    "\n",
    "# learning rate\n",
    "lr = 1e-3\n",
    "\n",
    "reg = 0.0001\n",
    "\n",
    "# discount factor in reinforcement learning\n",
    "gamma = 1\n",
    "\n",
    "# random action probability\n",
    "rand_action_prob = 0.05\n",
    "\n",
    "batches_per_print = 10*5\n",
    "\n",
    "# dummy initial cash\n",
    "initial_cash = 10000\n",
    "\n",
    "# checkpoint folder\n",
    "checkpoint_dir = '../../model_checkpoint/'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "# glob_mode should be assigned to None if an epoch finished\n",
    "glob_mode = None\n",
    "sample_start_index = None\n",
    "curr_pairs = None\n",
    "def get_random_history(batch_size, mode):\n",
    "    \"\"\"Sample some pairs and get the history of those pairs. The history should have\n",
    "    three dimension. The first dimension is for time. The second dimension is indexed\n",
    "    by features name. The third dimension is the index of training instance.\n",
    "    \"\"\"\n",
    "    global glob_mode\n",
    "    global sample_start_index\n",
    "    global curr_pairs\n",
    "    \n",
    "    if mode == 'train': # user intended to use training data\n",
    "        # first batch of training data\n",
    "        # shuffle the data first before sampling\n",
    "        if glob_mode != 'train':\n",
    "            glob_mode = 'train'\n",
    "            random.shuffle(all_pairs_slices_train)\n",
    "            sample_start_index = 0\n",
    "        sample_end_index = sample_start_index+batch_size\n",
    "        sample_pair_slices = all_pairs_slices_train[sample_start_index:sample_end_index]\n",
    "\n",
    "        # end of one epoch\n",
    "        if sample_end_index >= len(all_pairs_slices_train):\n",
    "            glob_mode = None\n",
    "\n",
    "    elif mode == 'valid': # user intended to use validation data\n",
    "        # first batch of validation data\n",
    "        # shuffle the data first before sampling\n",
    "        if glob_mode != 'valid':\n",
    "            glob_mode = 'valid'\n",
    "            random.shuffle(all_pairs_slices_valid)\n",
    "            sample_start_index = 0\n",
    "        sample_end_index = sample_start_index+batch_size\n",
    "        sample_pair_slices = all_pairs_slices_valid[sample_start_index:sample_end_index]\n",
    "\n",
    "        # end of one epoch\n",
    "        if sample_end_index >= len(all_pairs_slices_valid):\n",
    "            glob_mode = None\n",
    "    elif mode == 'test': # user intended to use validation data\n",
    "        # first batch of test data\n",
    "        # shuffle the data first before sampling\n",
    "        if glob_mode != 'test':\n",
    "            glob_mode = 'test'\n",
    "            random.shuffle(all_pairs_slices_test)\n",
    "            sample_start_index = 0\n",
    "        sample_end_index = sample_start_index+batch_size\n",
    "        sample_pair_slices = all_pairs_slices_test[sample_start_index:sample_end_index]\n",
    "\n",
    "        # end of one epoch\n",
    "        if sample_end_index >= len(all_pairs_slices_test):\n",
    "            glob_mode = None\n",
    "    else:\n",
    "        raise Exception(\"mode should be in ['train', 'valid', 'test'].\")\n",
    "    \n",
    "    curr_pairs = sample_pair_slices\n",
    "    \n",
    "    # update index for next batch\n",
    "    sample_start_index += batch_size\n",
    "    \n",
    "    # return to the environment. this should be no greater than batch_size\n",
    "    actual_batch_size = len(sample_pair_slices)\n",
    "    \n",
    "    history = []\n",
    "    for s in sample_pair_slices:\n",
    "        df = pd.read_csv(join(dataset_folder_path, s+\".csv\"))\n",
    "        df_val = df[df_columns].values\n",
    "        history.append(df_val)\n",
    "    \n",
    "    history = np.array(history)\n",
    "    return np.transpose(history, (1, 2, 0)), actual_batch_size\n",
    "\n",
    "def compute_input_history(history):\n",
    "    \"\"\"Slicing history in its second dimension.\"\"\"\n",
    "    # no slicing for now\n",
    "    return history[:,2:]\n",
    "\n",
    "def sample_action(logits, random=False, batch_size=batch_size):\n",
    "    if random:\n",
    "        dist = tf.distributions.Categorical(logits=tf.zeros([batch_size, a_num]))\n",
    "    else:\n",
    "        dist = tf.distributions.Categorical(logits=logits)\n",
    "    \n",
    "    # 1-D Tensor where the i-th element correspond to a sample from\n",
    "    # the i-th categorical distribution\n",
    "    return dist.sample()\n",
    "\n",
    "def long_portfolio_value(q, p):\n",
    "    return q*p\n",
    "\n",
    "def short_portfolio_value(q, p, init_p):\n",
    "    return q*(3.0*init_p/2 - p)\n",
    "\n",
    "# def discount_rewards(r, all_actions):\n",
    "#     \"\"\"\n",
    "#     r is a numpy array in the shape of (n, batch_size).\n",
    "#     all_actions is a numpy array in the same shape as r.\n",
    "    \n",
    "#     return the discounted and cumulative rewards\"\"\"\n",
    "    \n",
    "#     result = np.zeros_like(r, dtype=float)\n",
    "#     n = r.shape[0]\n",
    "#     sum_ = np.zeros_like(r[0], dtype=float)\n",
    "#     pre_action = all_actions[n-1]\n",
    "#     for i in range(n-1,-1,-1):\n",
    "#         sum_ *= gamma\n",
    "        \n",
    "#         # when the previous action(position) not equal to the current one,\n",
    "#         # set the previous sum of reward to be zero.\n",
    "#         sum_ = sum_*(all_actions[i]==pre_action) + r[i]\n",
    "#         result[i] = sum_\n",
    "        \n",
    "#         # update pre_action\n",
    "#         pre_action = all_actions[i]\n",
    "    \n",
    "#     return result\n",
    "\n",
    "def discount_rewards(r):\n",
    "    \"\"\"\n",
    "    r is a numpy array in the shape of (n, batch_size).\n",
    "    \n",
    "    return the discounted and cumulative rewards\"\"\"\n",
    "    \n",
    "    result = np.zeros_like(r, dtype=float)\n",
    "    n = r.shape[0]\n",
    "    sum_ = np.zeros_like(r[0], dtype=float)\n",
    "    for i in range(n-1,-1,-1):\n",
    "        sum_ *= gamma\n",
    "        sum_ += r[i]\n",
    "        result[i] = sum_\n",
    "    \n",
    "    return result\n",
    "\n",
    "def loss(all_logits, all_actions, all_advantages):\n",
    "    neg_log_select_prob = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=all_logits, labels=all_actions)\n",
    "    \n",
    "    # 0 axis is the time axis. 1 axis is the batch axis\n",
    "    return tf.reduce_mean(neg_log_select_prob * all_advantages, 0)\n",
    "\n",
    "def extract_pair_name(s):\n",
    "    return '_'.join(s.split('-')[:2])\n",
    "\n",
    "def extract_pair_index(s):\n",
    "    return int(s.split('-')[-1])\n",
    "\n",
    "def save_model():\n",
    "    hkg_time = datetime.now() + timedelta(hours=16)\n",
    "    checkpoint_name = hkg_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    checkpoint_prefix = os.path.join(checkpoint_dir, checkpoint_name)\n",
    "    root.save(checkpoint_prefix)\n",
    "    tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    \n",
    "def restore_model(checkpoint_name):\n",
    "    root.restore(join(checkpoint_dir, checkpoint_name))\n",
    "\n",
    "\n",
    "myLeakyReLU = tf.keras.layers.LeakyReLU()\n",
    "myLeakyReLU.__name__ = \"myLeakyReLU\"\n",
    "\n",
    "# classes\n",
    "class TradingPolicyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(TradingPolicyModel, self).__init__()\n",
    "        self.dense1 = tf.layers.Dense(units=layer1_out_num,\n",
    "                                      activation=myLeakyReLU,\n",
    "                                      kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                      kernel_regularizer=tf.contrib.layers.l2_regularizer(reg)\n",
    "                                     )\n",
    "        self.dense2 = tf.layers.Dense(units=layer1_out_num,\n",
    "                                      activation=myLeakyReLU,\n",
    "                                      kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                      kernel_regularizer=tf.contrib.layers.l2_regularizer(reg)\n",
    "                                     )\n",
    "        self.dense3 = tf.layers.Dense(units=layer1_out_num,\n",
    "                                      activation=myLeakyReLU,\n",
    "                                      kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                      kernel_regularizer=tf.contrib.layers.l2_regularizer(reg)\n",
    "                                     )\n",
    "#         self.dense4 = tf.layers.Dense(units=layer1_out_num,\n",
    "#                                       activation=tf.keras.layers.LeakyReLU(),\n",
    "#                                       kernel_initializer=tf.contrib.layers.xavier_initializer()\n",
    "#                                      )\n",
    "        self.logits = tf.layers.Dense(units=a_num,\n",
    "                                      activation=myLeakyReLU,\n",
    "                                      kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                      kernel_regularizer=tf.contrib.layers.l2_regularizer(reg)\n",
    "                                     )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Forward pass\n",
    "        inputs = self.dense1(inputs)\n",
    "        inputs = self.dense2(inputs)\n",
    "        inputs = self.dense3(inputs)\n",
    "#         inputs = self.dense4(inputs)\n",
    "        logits = self.logits(inputs)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class StateEncodingModel(tf.keras.Model):\n",
    "    def __init__(self, batch_size=batch_size):\n",
    "        super(StateEncodingModel, self).__init__()\n",
    "        self.cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.LSTMCell(h_dim) for i in range(num_layers)])\n",
    "        self.reset_state(batch_size)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        output, self.state = self.cell(inputs, self.state)\n",
    "        return output\n",
    "        \n",
    "    def reset_state(self, batch_size=batch_size):\n",
    "        self.state = self.cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "\n",
    "class TradingEnvironment():\n",
    "    \"\"\"Trading environment for reinforcement learning training.\n",
    "    \n",
    "    NOTE: Call reset first before calling step!\n",
    "    \n",
    "    Arguments:\n",
    "        state_encoding_model: the model that encode past input_history data into a state\n",
    "        vector which will be fed as input to the policy network.\n",
    "    \"\"\"\n",
    "    def __init__(self, state_encoding_model):\n",
    "        # do some initialization\n",
    "        self.state_encoding_model = state_encoding_model\n",
    "        \n",
    "    def _reset_env(self, mode, batch_size=batch_size):\n",
    "        \n",
    "        # prepare a batch of history and input_history\n",
    "        # actual batch_size depends on the dataset\n",
    "        self.history, curr_batch_size = get_random_history(batch_size, mode)\n",
    "        batch_size = curr_batch_size\n",
    "        self.input_history = compute_input_history(self.history)\n",
    "        \n",
    "        self.t = 0\n",
    "        self.state_encoding_model.reset_state(batch_size)\n",
    "\n",
    "        # 0 is no position. 1 is long the spread. 2 is short the spread\n",
    "        self.position = np.zeros(batch_size, dtype=int)\n",
    "        \n",
    "        # initialize the cash each agent has\n",
    "        self.total_portfolio_value = np.ones(batch_size)*initial_cash\n",
    "        \n",
    "        # only useful when there is a postion on the spread\n",
    "        self.quantity = {'x': np.zeros(batch_size), 'y': np.zeros(batch_size)}\n",
    "        \n",
    "        # for compute current portfolio value of the short side\n",
    "        self.short_side_init_price = np.zeros(batch_size)\n",
    "        \n",
    "        # create or update self.state variable\n",
    "        self.update_state()\n",
    "    \n",
    "    def reset(self, mode):\n",
    "        \"\"\"Return an initial state for the trading environment\"\"\"\n",
    "        \n",
    "        # determine what dataset to use\n",
    "        self._reset_env(mode)\n",
    "        return self.state\n",
    "    \n",
    "    def compute_reward(self, action):\n",
    "        \"\"\"Compute the reward at time t which is the change in total portfolio value\n",
    "        from time t to t+1. It also update the position for time t+1. Exit trade when\n",
    "        the short side portfolio value <= 0.\"\"\"\n",
    "        \n",
    "        r = np.zeros_like(action, dtype=float)\n",
    "        cur_his = self.history[self.t]\n",
    "        nex_his = self.history[self.t+1]\n",
    "        \n",
    "        # compute for each training instance in a batch\n",
    "        for i, a in enumerate(action):\n",
    "            y_p = cur_his[ind[\"y_close\"], i]\n",
    "            x_p = cur_his[ind[\"x_close\"], i]\n",
    "            nex_y_p = nex_his[ind[\"y_close\"], i]\n",
    "            nex_x_p = nex_his[ind[\"x_close\"], i]\n",
    "            \n",
    "            \n",
    "            if a == 0: # take no position on the spread\n",
    "                # no change in portfolio value\n",
    "                r[i] = 0\n",
    "                self.position[i] = 0\n",
    "                self.quantity['y'][i] = 0.0\n",
    "                self.quantity['x'][i] = 0.0\n",
    "            elif a == 1: # long the spread: long Y and short X\n",
    "                # quantity of each stock will change when the current position is not previous position\n",
    "                if self.position[i] == 0 or self.position[i] == 2:\n",
    "                    # compute quantity from cash\n",
    "                    self.quantity['y'][i] = 2.0*self.total_portfolio_value[i]/3.0/y_p\n",
    "                    self.quantity['x'][i] = 2.0*self.total_portfolio_value[i]/3.0/x_p\n",
    "                    self.short_side_init_price[i] = x_p\n",
    "\n",
    "                lpv = long_portfolio_value(self.quantity['y'][i], nex_y_p)\n",
    "                spv = short_portfolio_value(self.quantity['x'][i], nex_x_p, self.short_side_init_price[i])\n",
    "                \n",
    "                # the zero here can be changed to other positive threshold ...\n",
    "                if spv <= 0:\n",
    "                    # we loss all the money in the short side\n",
    "                    nex_portfolio_value = lpv\n",
    "\n",
    "                    # forced to take position 0\n",
    "                    self.position[i] = 0\n",
    "                else:\n",
    "                    nex_portfolio_value = lpv + spv\n",
    "                    self.position[i] = 1\n",
    "                \n",
    "                r[i] = nex_portfolio_value - self.total_portfolio_value[i]\n",
    "                self.total_portfolio_value[i] = nex_portfolio_value\n",
    "            elif a == 2: # short the spread: short Y and long X\n",
    "                # quantity will change when the current position is not previous position\n",
    "                if self.position[i] == 0 or self.position[i] == 1:\n",
    "                    # compute quantity from cash\n",
    "                    self.quantity['y'][i] = 2.0*self.total_portfolio_value[i]/3.0/y_p\n",
    "                    self.quantity['x'][i] = 2.0*self.total_portfolio_value[i]/3.0/x_p\n",
    "                    self.short_side_init_price[i] = y_p\n",
    "\n",
    "                lpv = long_portfolio_value(self.quantity['x'][i], nex_x_p)\n",
    "                spv = short_portfolio_value(self.quantity['y'][i], nex_y_p, self.short_side_init_price[i])\n",
    "                \n",
    "                if spv <= 0:\n",
    "                    # we loss all the money in the short side\n",
    "                    nex_portfolio_value = lpv\n",
    "\n",
    "                    # forced to take position 0\n",
    "                    self.position[i] = 0\n",
    "                else:\n",
    "                    nex_portfolio_value = lpv + spv\n",
    "                    self.position[i] = 2\n",
    "                \n",
    "                r[i] = nex_portfolio_value - self.total_portfolio_value[i]\n",
    "                self.total_portfolio_value[i] = nex_portfolio_value\n",
    "        return r\n",
    "    \n",
    "    def update_state(self):\n",
    "#         # concate next_input_history and next position to form next partial state\n",
    "#         partial_state = tf.concat([self.input_history[self.t].T, tf.one_hot(self.position, position_num)], 1)\n",
    "        \n",
    "#         # update state\n",
    "#         self.state = self.state_encoding_model(partial_state)\n",
    "\n",
    "        observation = tf.convert_to_tensor(self.input_history[self.t].T, dtype=tf.float32)\n",
    "    \n",
    "        # use rnn to encode observationans and current stock state into next stock state\n",
    "        stock_state = self.state_encoding_model(observation)\n",
    "        \n",
    "        # do normalization for total_portfolio_value\n",
    "        # this is extremely important. if not normalized, the action will be highly biased.\n",
    "        portfolio_state = np.array([\n",
    "            self.total_portfolio_value/initial_cash,\n",
    "#             self.quantity['y'],\n",
    "#             self.quantity['x']\n",
    "        ]).T\n",
    "        \n",
    "        # stock state and portfolio state together form the whole environment state\n",
    "        self.state = tf.concat([\n",
    "            stock_state,\n",
    "            portfolio_state,\n",
    "            tf.one_hot(self.position, position_num)\n",
    "        ], 1)\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"Given the current state and action, return the reward, next state and done.\n",
    "        This function should be called after reset.\n",
    "        \n",
    "        reward is of type numpy array. state is of type tensor. done is of type boolean.\n",
    "        \n",
    "        \n",
    "        Arguments:\n",
    "            action: a numpy array containing the current action for each training pair.\n",
    "\n",
    "        Note that we follow the convention where the trajectory is indexed as s_0, a_0, r_0,\n",
    "        s_1, ... . Therefore t is updated just after computing the reward is computed and\n",
    "        before computing next state.\n",
    "        \"\"\"\n",
    "        # r_t\n",
    "        r = self.compute_reward(action) # also update the position for time t+1\n",
    "\n",
    "        # t = t+1\n",
    "        self.t += 1\n",
    "        \n",
    "        # compute s_(t+1)\n",
    "        self.update_state()\n",
    "\n",
    "        return r, self.state, (self.t+1) == trading_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create objects\n",
    "pi = TradingPolicyModel()\n",
    "state_encoding_model = StateEncodingModel()\n",
    "env = TradingEnvironment(state_encoding_model)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "\n",
    "# create checkpoint object\n",
    "root = tf.train.Checkpoint(pi=pi, state_encoding_model=state_encoding_model, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batch_for_evaluate_performance(reward_list, mode):\n",
    "    done = False\n",
    "    s = env.reset(mode)\n",
    "\n",
    "    # for accumalting episode statistics\n",
    "    act_batch_size = tf.shape(s).numpy()[0]\n",
    "    total_r = np.zeros(act_batch_size)\n",
    "\n",
    "    # internally the episode length is fixed by trading_period\n",
    "    while not done:\n",
    "        logits = pi(s)\n",
    "        a = sample_action(logits, batch_size=act_batch_size)\n",
    "\n",
    "        # get immediate reward, update state, and get done\n",
    "        r, s, done = env.step(a.numpy())\n",
    "\n",
    "#         # for debugging\n",
    "#         print('logits:', logits[0])\n",
    "#         print('a:', a.numpy())\n",
    "#         print('s:', s[0])\n",
    "#         print('r:', r[0])\n",
    "\n",
    "        total_r += r\n",
    "    reward_list += total_r.tolist()\n",
    "    return {extract_pair_name(curr_pairs[i]): total_r[i] for i in range(act_batch_size)}\n",
    "\n",
    "\n",
    "def run_epoch_for_evaluate_performance(rs, total_r_dict, mode):\n",
    "    counter = 0\n",
    "    temp_dict = run_batch_for_evaluate_performance(rs, mode)\n",
    "    total_r_dict.update(temp_dict)\n",
    "    print('{}, '.format(counter), end='')\n",
    "    counter += 1\n",
    "    while glob_mode != None:\n",
    "        temp_dict = run_batch_for_evaluate_performance(rs, mode)\n",
    "        total_r_dict.update(temp_dict)\n",
    "        print('{}, '.format(counter), end='')\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 79.20933640675466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  4.,  41., 134., 385., 522., 432., 252., 127.,  58.,  21.,  12.,\n",
       "          9.,   1.,   0.,   0.,   0.,   1.,   0.,   0.,   1.]),\n",
       " array([-7170.89328853, -5726.40729048, -4281.92129243, -2837.43529438,\n",
       "        -1392.94929633,    51.53670172,  1496.02269977,  2940.50869782,\n",
       "         4384.99469587,  5829.48069392,  7273.96669197,  8718.45269002,\n",
       "        10162.93868807, 11607.42468612, 13051.91068417, 14496.39668222,\n",
       "        15940.88268027, 17385.36867832, 18829.85467637, 20274.34067442,\n",
       "        21718.82667247]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15173cca7278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate performance on train dataset\n",
    "train_rs = []\n",
    "train_total_r_dict = {}\n",
    "run_epoch_for_evaluate_performance(train_rs, train_total_r_dict, 'train')\n",
    "\n",
    "print(np.mean(train_rs))\n",
    "plt.hist(train_rs, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_of_pair = 1000\n",
      "batch_size = 100\n",
      "num_of_batch = 400, estimated epoch = 20.0\n",
      "rand_action_prob = 0.05\n",
      "lr = 0.001\n",
      "average total_r over one epoch: 90.79\n",
      "average total_r over one epoch: 213.56\n",
      "batch_id: 49, num_eps_over: 5000, average_total_r_per_ep: 153.15, time_spent: 72.3s\n",
      "average total_r over one epoch: 164.12\n",
      "average total_r over one epoch: 496.12\n",
      "batch_id: 99, num_eps_over: 5000, average_total_r_per_ep: 508.60, time_spent: 72.2s\n",
      "average total_r over one epoch: 689.78\n",
      "average total_r over one epoch: 702.94\n",
      "average total_r over one epoch: 875.91\n",
      "batch_id: 149, num_eps_over: 5000, average_total_r_per_ep: 815.83, time_spent: 72.2s\n",
      "average total_r over one epoch: 1064.79\n",
      "average total_r over one epoch: 1024.14\n",
      "batch_id: 199, num_eps_over: 5000, average_total_r_per_ep: 1062.94, time_spent: 72.5s\n",
      "average total_r over one epoch: 1029.14\n",
      "average total_r over one epoch: 1211.14\n",
      "average total_r over one epoch: 956.97\n",
      "batch_id: 249, num_eps_over: 5000, average_total_r_per_ep: 1047.21, time_spent: 71.7s\n",
      "average total_r over one epoch: 883.36\n",
      "average total_r over one epoch: 1165.59\n",
      "batch_id: 299, num_eps_over: 5000, average_total_r_per_ep: 1202.78, time_spent: 71.0s\n",
      "average total_r over one epoch: 1407.89\n",
      "average total_r over one epoch: 1271.20\n",
      "average total_r over one epoch: 1287.84\n",
      "batch_id: 349, num_eps_over: 5000, average_total_r_per_ep: 1254.89, time_spent: 71.1s\n",
      "average total_r over one epoch: 1105.28\n",
      "average total_r over one epoch: 1104.24\n",
      "batch_id: 399, num_eps_over: 5000, average_total_r_per_ep: 1099.53, time_spent: 70.9s\n",
      "average total_r over one epoch: 1117.48\n",
      "Finished training~\n"
     ]
    }
   ],
   "source": [
    "# print parameters\n",
    "print('num_of_pair =', num_of_pair)\n",
    "print('batch_size =', batch_size)\n",
    "print('num_of_batch = {}, estimated epoch = {}'.format(num_of_batch, num_of_batch*batch_size/2/num_of_pair))\n",
    "print('rand_action_prob =', rand_action_prob)\n",
    "print('lr =', lr)\n",
    "\n",
    "# for training reference only\n",
    "average_total_r = 0.0\n",
    "epoch_average_total_r = 0.0\n",
    "num_eps_over = 0\n",
    "total_r_dict = {}\n",
    "\n",
    "start_time = time.time()\n",
    "for batch in range(num_of_batch):\n",
    "    \n",
    "    with tf.GradientTape() as gt:\n",
    "        # saving for update\n",
    "        all_logits = []\n",
    "        all_actions = []\n",
    "        all_rewards = []\n",
    "        \n",
    "        # episode starts here~\n",
    "        done = False\n",
    "        s = env.reset('train')\n",
    "        \n",
    "        # for accumalting episode statistics\n",
    "        act_batch_size = tf.shape(s).numpy()[0]\n",
    "        num_eps_over += act_batch_size\n",
    "        total_r = np.zeros(act_batch_size)\n",
    "\n",
    "        # internally the episode length is fixed by trading_period\n",
    "        while not done:\n",
    "            logits = pi(s)\n",
    "            a = sample_action(logits, random=np.random.rand() <= rand_action_prob,\n",
    "                              batch_size=act_batch_size)\n",
    "            r, s, done = env.step(a.numpy())\n",
    "\n",
    "            # save the episode\n",
    "            all_logits.append(logits)\n",
    "            all_actions.append(a)\n",
    "            all_rewards.append(r)\n",
    "            \n",
    "            r_sum = np.sum(r)\n",
    "            average_total_r += r_sum\n",
    "            epoch_average_total_r += r_sum\n",
    "            total_r += r\n",
    "            \n",
    "#             # debugging\n",
    "#             print(env.t)\n",
    "#             print(env.t+1==200)\n",
    "#             print(r[0])\n",
    "#             print('a:', a.numpy())\n",
    "#             print(env.total_portfolio_value[0])\n",
    "#             print(done)\n",
    "#             print(logits)\n",
    "\n",
    "        # keep track of the pair performance (of course this is not totally fair for all pairs\n",
    "        # as there are parameters update).\n",
    "        total_r_dict.update({curr_pairs[i]: total_r[i] for i in range(act_batch_size)})\n",
    "\n",
    "        all_logits_stack = tf.stack(all_logits)\n",
    "        all_actions_stack = tf.stack(all_actions)\n",
    "        all_rewards_stack = np.array(all_rewards)\n",
    "        \n",
    "        # compute cummulative rewards for each action\n",
    "        all_cum_rewards = discount_rewards(all_rewards_stack)\n",
    "#         all_cum_rewards -= np.mean(all_cum_rewards)\n",
    "#         all_cum_rewards /= np.std(all_cum_rewards)\n",
    "        all_cum_rewards /= np.mean(np.abs(all_cum_rewards))\n",
    "        all_cum_rewards = tf.convert_to_tensor(all_cum_rewards, dtype=tf.float32)\n",
    "\n",
    "        loss_value = loss(all_logits_stack, all_actions_stack, all_cum_rewards)\n",
    "    \n",
    "    grads = gt.gradient(loss_value, state_encoding_model.variables + pi.variables)\n",
    "    optimizer.apply_gradients(zip(grads, state_encoding_model.variables + pi.variables))\n",
    "    \n",
    "    if (batch+1) % batches_per_print == 0:\n",
    "        end_time = time.time()\n",
    "        print((\"batch_id: {}, num_eps_over: {}, average_total_r_per_ep: {:.2f}, \"+\n",
    "               \"time_spent: {:.1f}s\").format(\n",
    "            batch, num_eps_over, average_total_r/num_eps_over, end_time-start_time))\n",
    "        \n",
    "        # reset\n",
    "        average_total_r = 0.0\n",
    "        num_eps_over = 0\n",
    "        start_time = time.time()\n",
    "    \n",
    "    # print epoch summary\n",
    "    if glob_mode == None:\n",
    "        # compute average total reward in one epoch to evaluate agent performance\n",
    "        print(\"average total_r over one epoch: {:.2f}\".format(\n",
    "            epoch_average_total_r/len(total_r_dict)))\n",
    "        \n",
    "        # reset\n",
    "        epoch_average_total_r = 0.0\n",
    "        total_r_dict = {}\n",
    "        \n",
    "print('Finished training~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2000\n",
      "1210.700675068718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  1.,   1.,  31.,  87., 227., 323., 434., 348., 218., 168.,  67.,\n",
       "         37.,  21.,  14.,  13.,   3.,   1.,   2.,   3.,   1.]),\n",
       " array([-7451.99543813, -6214.31853571, -4976.64163329, -3738.96473087,\n",
       "        -2501.28782845, -1263.61092603,   -25.93402361,  1211.74287881,\n",
       "         2449.41978123,  3687.09668365,  4924.77358607,  6162.45048848,\n",
       "         7400.1273909 ,  8637.80429332,  9875.48119574, 11113.15809816,\n",
       "        12350.83500058, 13588.511903  , 14826.18880542, 16063.86570784,\n",
       "        17301.54261026]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9JJU3P8DqXf/l+YmRoMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15173cc84160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate performance on train dataset\n",
    "train_rs = []\n",
    "train_total_r_dict = {}\n",
    "run_epoch_for_evaluate_performance(train_rs, train_total_r_dict, 'train')\n",
    "\n",
    "print(len(train_rs))\n",
    "print(np.mean(train_rs))\n",
    "plt.hist(train_rs, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1000\n",
      "820.0720067298778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  9.,  15.,  63., 120., 173., 185., 157.,  98.,  64.,  47.,  28.,\n",
       "         15.,  15.,   5.,   3.,   0.,   2.,   0.,   0.,   1.]),\n",
       " array([-5037.88031017, -4054.25507546, -3070.62984076, -2087.00460605,\n",
       "        -1103.37937135,  -119.75413664,   863.87109807,  1847.49633277,\n",
       "         2831.12156748,  3814.74680218,  4798.37203689,  5781.99727159,\n",
       "         6765.6225063 ,  7749.247741  ,  8732.87297571,  9716.49821042,\n",
       "        10700.12344512, 11683.74867983, 12667.37391453, 13650.99914924,\n",
       "        14634.62438394]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15173c59ccf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate performance on valid dataset\n",
    "valid_rs = []\n",
    "valid_total_r_dict = {}\n",
    "run_epoch_for_evaluate_performance(valid_rs, valid_total_r_dict, 'valid')\n",
    "\n",
    "print(len(valid_rs))\n",
    "print(np.mean(valid_rs))\n",
    "plt.hist(valid_rs, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1000\n",
      "949.563467634051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  3.,   4.,  21.,  91., 241., 277., 184.,  92.,  49.,  20.,   9.,\n",
       "          1.,   1.,   2.,   2.,   0.,   1.,   1.,   0.,   1.]),\n",
       " array([-7559.62641969, -6067.68828346, -4575.75014723, -3083.81201099,\n",
       "        -1591.87387476,   -99.93573853,  1392.00239771,  2883.94053394,\n",
       "         4375.87867017,  5867.81680641,  7359.75494264,  8851.69307887,\n",
       "        10343.6312151 , 11835.56935134, 13327.50748757, 14819.4456238 ,\n",
       "        16311.38376004, 17803.32189627, 19295.2600325 , 20787.19816874,\n",
       "        22279.13630497]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nldlfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15173c3f3080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate performance on test dataset\n",
    "test_rs = []\n",
    "test_total_r_dict = {}\n",
    "run_epoch_for_evaluate_performance(test_rs, test_total_r_dict, 'test')\n",
    "\n",
    "print(len(test_rs))\n",
    "print(np.mean(test_rs))\n",
    "plt.hist(test_rs, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAHVCAYAAABi9BP7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15173c16a908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "K = 10\n",
    "train_total_r_ordered = sorted(list(train_total_r_dict.items()), key=lambda x: x[1], reverse=True)\n",
    "train_total_r_ordered_sliced = train_total_r_ordered[:K]\n",
    "valid_total_r_corresponding_value = [valid_total_r_dict[x[0]] for x in train_total_r_ordered_sliced]\n",
    "train_total_r_sliced_value = [x[1] for x in train_total_r_ordered_sliced]\n",
    "\n",
    "# see if the model overfits a lot by checking the performace in valid of best K pairs in train\n",
    "bins = np.linspace(-10000, 20000, 30)\n",
    "plt.hist(train_total_r_sliced_value, bins, alpha=0.3, label='train')\n",
    "plt.hist(valid_total_r_corresponding_value, bins, alpha=0.3, label='valid')\n",
    "plt.legend(loc='upper right')\n",
    "plt.gcf().set_size_inches(15, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel, 2018 update 2)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_2018u2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
