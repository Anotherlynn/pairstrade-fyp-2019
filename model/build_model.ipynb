{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# fixed number of time steps in one episode\n",
    "trading_period = 60\n",
    "\n",
    "# 1 is zscore, the other 3 is one-hot encoding of the current postion of the trading algorithm\n",
    "state_dim = 1+3\n",
    "\n",
    "# RNN hidden state dimension\n",
    "h_dim = 20\n",
    "\n",
    "# number of actions\n",
    "a_num = 4\n",
    "\n",
    "# number of layer1 output\n",
    "layer1_out_num = 100\n",
    "\n",
    "# learning rate\n",
    "lr = 1e-3\n",
    "\n",
    "# update batch size\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# policy network\n",
    "o = tf.placeholder(tf.float32, [None, h_dim] , name=\"observations\")\n",
    "\n",
    "layer1 = tf.layers.Dense(units=layer1_out_num,\n",
    "                         activation=tf.keras.layers.LeakyReLU(),\n",
    "                         kernel_initializer=tf.contrib.layers.xavier_initializer()\n",
    "                        )(o)\n",
    "\n",
    "scores = tf.layers.Dense(units=a_num,\n",
    "                         activation=tf.keras.layers.LeakyReLU(),\n",
    "                         kernel_initializer=tf.contrib.layers.xavier_initializer()\n",
    "                        )(layer1)\n",
    "\n",
    "# train only the weights above\n",
    "t_vars = tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(20, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'dense/bias:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(100, 4) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(4,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for sampling an action during a episode\n",
    "action_probs = tf.nn.softmax(scores)\n",
    "\n",
    "# chosen actions\n",
    "input_actions = tf.placeholder(tf.int32, [None], name=\"action_label\")\n",
    "advantages = tf.placeholder(tf.float32, [None], name=\"adjusted_reward_signal\")\n",
    "\n",
    "neg_log_select_prob = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=scores, labels=input_actions)\n",
    "loss = tf.reduce_mean(neg_log_select_prob * advantages)\n",
    "grads = tf.gradients(loss, t_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'gradients/dense/MatMul_grad/MatMul_1:0' shape=(20, 100) dtype=float32>,\n",
       " <tf.Tensor 'gradients/dense/BiasAdd_grad/BiasAddGrad:0' shape=(100,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/dense_1/MatMul_grad/MatMul_1:0' shape=(100, 4) dtype=float32>,\n",
       " <tf.Tensor 'gradients/dense_1/BiasAdd_grad/BiasAddGrad:0' shape=(4,) dtype=float32>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accum_grads = [tf.Variable(tf.zeros_like(tv.initialized_value()), trainable=False)\n",
    "               for tv in t_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(20, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_1:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_2:0' shape=(100, 4) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_3:0' shape=(4,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accum_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_grads = [grad.assign(tf.zeros_like(grad))\n",
    "               for grad in accum_grads]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Assign:0' shape=(20, 100) dtype=float32_ref>,\n",
       " <tf.Tensor 'Assign_1:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Tensor 'Assign_2:0' shape=(100, 4) dtype=float32_ref>,\n",
       " <tf.Tensor 'Assign_3:0' shape=(4,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate_batch = [accum_grad.assign_add(grad/batch_size)\n",
    "                  for accum_grad, grad in zip(accum_grads, grads)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'AssignAdd:0' shape=(20, 100) dtype=float32_ref>,\n",
       " <tf.Tensor 'AssignAdd_1:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Tensor 'AssignAdd_2:0' shape=(100, 4) dtype=float32_ref>,\n",
       " <tf.Tensor 'AssignAdd_3:0' shape=(4,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "apply_grads = adam.apply_gradients(zip(accum_grads, t_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output the default graph which can be viewed on tensorboard\n",
    "writer = tf.summary.FileWriter('.')\n",
    "writer.add_graph(tf.get_default_graph())\n",
    "writer.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
